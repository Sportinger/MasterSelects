// Timeline component - Video editing timeline with tracks and clips

import { useRef, useState, useCallback, useEffect } from 'react';
import { useTimelineStore } from '../stores/timelineStore';
import type { AnimatableProperty, BlendMode } from '../types';

// All blend modes in order for cycling with Shift + "+"
const ALL_BLEND_MODES: BlendMode[] = [
  // Normal
  'normal', 'dissolve', 'dancing-dissolve',
  // Darken
  'darken', 'multiply', 'color-burn', 'classic-color-burn', 'linear-burn', 'darker-color',
  // Lighten
  'add', 'lighten', 'screen', 'color-dodge', 'classic-color-dodge', 'linear-dodge', 'lighter-color',
  // Contrast
  'overlay', 'soft-light', 'hard-light', 'linear-light', 'vivid-light', 'pin-light', 'hard-mix',
  // Inversion
  'difference', 'classic-difference', 'exclusion', 'subtract', 'divide',
  // Component
  'hue', 'saturation', 'color', 'luminosity',
  // Stencil
  'stencil-alpha', 'stencil-luma', 'silhouette-alpha', 'silhouette-luma', 'alpha-add',
];
import { useMixerStore } from '../stores/mixerStore';
import { useMediaStore } from '../stores/mediaStore';
import { engine } from '../engine/WebGPUEngine';
import { proxyFrameCache } from '../services/proxyFrameCache';

export function Timeline() {
  const {
    tracks,
    clips,
    playheadPosition,
    duration,
    zoom,
    scrollX,
    isPlaying,
    selectedClipId,
    inPoint,
    outPoint,
    addTrack,
    addClip,
    addCompClip,
    moveClip,
    trimClip,
    removeClip,
    selectClip,
    setPlayheadPosition,
    setZoom,
    setScrollX,
    play,
    pause,
    stop,
    setInPoint,
    setOutPoint,
    setInPointAtPlayhead,
    setOutPointAtPlayhead,
    clearInOut,
    getSnappedPosition,
    findNonOverlappingPosition,
    loopPlayback,
    toggleLoopPlayback,
    ramPreviewProgress,
    ramPreviewRange,
    isRamPreviewing,
    startRamPreview,
    cancelRamPreview,
    clearRamPreview,
    getCachedRanges,
    isDraggingPlayhead,
    setDraggingPlayhead,
    ramPreviewEnabled,
    toggleRamPreviewEnabled,
    splitClipAtPlayhead,
    toggleClipReverse,
    updateClipTransform,
    getInterpolatedTransform,
    isTrackExpanded,
    toggleTrackExpanded,
    isTrackPropertyGroupExpanded,
    toggleTrackPropertyGroupExpanded,
    getExpandedTrackHeight,
    getClipKeyframes,
    selectKeyframe,
    selectedKeyframeIds,
    hasKeyframes,
    trackHasKeyframes,
    clipKeyframes,
  } = useTimelineStore();

  const {
    getActiveComposition,
    getOpenCompositions,
    proxyEnabled,
    setProxyEnabled,
    files: mediaFiles,
    currentlyGeneratingProxyId,
    proxyFolderName,
    pickProxyFolder,
    showInExplorer,
  } = useMediaStore();
  const activeComposition = getActiveComposition();
  const openCompositions = getOpenCompositions();

  const timelineRef = useRef<HTMLDivElement>(null);
  const trackLanesRef = useRef<HTMLDivElement>(null);

  // Premiere-style clip dragging state
  const [clipDrag, setClipDrag] = useState<{
    clipId: string;
    originalStartTime: number;
    originalTrackId: string;
    grabOffsetX: number;  // Where on the clip we grabbed (in pixels)
    currentX: number;     // Current mouse X position
    currentTrackId: string;
    snappedTime: number | null;  // Snapped position (if snapping)
    isSnapping: boolean;         // Whether currently snapping
  } | null>(null);

  // Ref to track clipDrag state for event handlers (avoids dependency issues)
  const clipDragRef = useRef(clipDrag);
  clipDragRef.current = clipDrag;

  // Clip trimming state
  const [clipTrim, setClipTrim] = useState<{
    clipId: string;
    edge: 'left' | 'right';
    originalStartTime: number;
    originalDuration: number;
    originalInPoint: number;
    originalOutPoint: number;
    startX: number;
    currentX: number;
    altKey: boolean;  // If true, don't trim linked clip
  } | null>(null);

  // Ref to track clipTrim state for event handlers (avoids dependency issues)
  const clipTrimRef = useRef(clipTrim);
  clipTrimRef.current = clipTrim;

  // In/Out marker drag state
  const [markerDrag, setMarkerDrag] = useState<{
    type: 'in' | 'out';
    startX: number;
    originalTime: number;
  } | null>(null);

  // External file drag preview state
  const [externalDrag, setExternalDrag] = useState<{
    trackId: string;
    startTime: number;
    x: number;
    y: number;
    audioTrackId?: string;  // Preview for linked audio clip
    isVideo?: boolean;      // Is the dragged file a video?
    duration?: number;      // Actual duration of dragged file
  } | null>(null);

  // Context menu state for clip right-click
  const [contextMenu, setContextMenu] = useState<{
    x: number;
    y: number;
    clipId: string;
  } | null>(null);
  const dragCounterRef = useRef(0); // Track drag enter/leave balance
  const dragDurationCacheRef = useRef<{ url: string; duration: number } | null>(null); // Cache duration during drag

  // Keyboard shortcuts (global, works regardless of focus)
  useEffect(() => {
    const handleKeyDown = (e: KeyboardEvent) => {
      // Only handle if not typing in an input
      if (e.target instanceof HTMLInputElement || e.target instanceof HTMLTextAreaElement) {
        return;
      }

      // Space: toggle play/pause
      if (e.code === 'Space' || e.key === ' ') {
        e.preventDefault();
        if (isPlaying) {
          pause();
        } else {
          play();
        }
        return;
      }

      // I: set In point at playhead
      if (e.key === 'i' || e.key === 'I') {
        e.preventDefault();
        setInPointAtPlayhead();
        return;
      }

      // O: set Out point at playhead
      if (e.key === 'o' || e.key === 'O') {
        e.preventDefault();
        setOutPointAtPlayhead();
        return;
      }

      // X: clear In/Out points
      if (e.key === 'x' || e.key === 'X') {
        e.preventDefault();
        clearInOut();
        return;
      }

      // L: toggle loop playback
      if (e.key === 'l' || e.key === 'L') {
        e.preventDefault();
        toggleLoopPlayback();
        return;
      }

      // Delete/Backspace: remove selected clip from timeline
      if (e.key === 'Delete' || e.key === 'Backspace') {
        e.preventDefault();
        if (selectedClipId) {
          removeClip(selectedClipId);
        }
        return;
      }

      // C: Cut/split clip at playhead position
      if (e.key === 'c' || e.key === 'C') {
        e.preventDefault();
        splitClipAtPlayhead();
        return;
      }

      // Shift + "+": Cycle through blend modes (forward)
      // Shift + "-": Cycle through blend modes (backward)
      if (e.shiftKey && (e.key === '+' || e.key === '=' || e.key === '-' || e.key === '_')) {
        e.preventDefault();
        if (selectedClipId) {
          const clip = clips.find(c => c.id === selectedClipId);
          if (clip) {
            const currentMode = clip.transform.blendMode;
            const currentIndex = ALL_BLEND_MODES.indexOf(currentMode);
            const direction = (e.key === '+' || e.key === '=') ? 1 : -1;
            const nextIndex = (currentIndex + direction + ALL_BLEND_MODES.length) % ALL_BLEND_MODES.length;
            const nextMode = ALL_BLEND_MODES[nextIndex];
            updateClipTransform(selectedClipId, { blendMode: nextMode });
          }
        }
        return;
      }
    };

    window.addEventListener('keydown', handleKeyDown);
    return () => window.removeEventListener('keydown', handleKeyDown);
  }, [isPlaying, play, pause, setInPointAtPlayhead, setOutPointAtPlayhead, clearInOut, toggleLoopPlayback, selectedClipId, removeClip, splitClipAtPlayhead, clips, updateClipTransform]);

  // Close context menu when clicking outside or pressing Escape
  useEffect(() => {
    if (!contextMenu) return;

    const handleClickOutside = () => {
      setContextMenu(null);
    };

    const handleKeyDown = (e: KeyboardEvent) => {
      if (e.key === 'Escape') {
        setContextMenu(null);
      }
    };

    // Delay adding click listener to avoid immediate close
    const timeoutId = setTimeout(() => {
      window.addEventListener('click', handleClickOutside);
    }, 0);
    window.addEventListener('keydown', handleKeyDown);

    return () => {
      clearTimeout(timeoutId);
      window.removeEventListener('click', handleClickOutside);
      window.removeEventListener('keydown', handleKeyDown);
    };
  }, [contextMenu]);

  // Handle right-click on clip
  const handleClipContextMenu = (e: React.MouseEvent, clipId: string) => {
    e.preventDefault();
    e.stopPropagation();

    // Select the clip on right-click
    selectClip(clipId);

    // Show context menu at mouse position
    setContextMenu({
      x: e.clientX,
      y: e.clientY,
      clipId,
    });
  };

  // Get the media file for a clip (helper function)
  const getMediaFileForClip = (clipId: string) => {
    const clip = clips.find(c => c.id === clipId);
    if (!clip) return null;

    const mediaStore = useMediaStore.getState();
    return mediaStore.files.find(f =>
      f.id === clip.source?.mediaFileId ||
      f.name === clip.name ||
      f.name === clip.name.replace(' (Audio)', '')
    );
  };

  // Handle "Show in Explorer" action
  const handleShowInExplorer = async (type: 'raw' | 'proxy') => {
    if (!contextMenu) return;

    const mediaFile = getMediaFileForClip(contextMenu.clipId);

    if (!mediaFile) {
      console.warn('[Timeline] Media file not found for clip');
      setContextMenu(null);
      return;
    }

    const result = await showInExplorer(type, mediaFile.id);

    if (result.success) {
      alert(result.message);
    } else {
      // Fallback: download the file for raw
      if (type === 'raw' && mediaFile.file) {
        const url = URL.createObjectURL(mediaFile.file);
        const a = document.createElement('a');
        a.href = url;
        a.download = mediaFile.name;
        document.body.appendChild(a);
        a.click();
        document.body.removeChild(a);
        URL.revokeObjectURL(url);
        console.log('[Timeline] Downloaded raw file:', mediaFile.name);
      } else {
        alert(result.message);
      }
    }

    setContextMenu(null);
  };

  // Handle Set Proxy Folder
  const handleSetProxyFolder = async () => {
    await pickProxyFolder();
    setContextMenu(null);
  };

  // Handle Start/Stop Proxy Generation
  const handleProxyGeneration = (action: 'start' | 'stop') => {
    if (!contextMenu) return;

    const mediaFile = getMediaFileForClip(contextMenu.clipId);
    if (!mediaFile) {
      setContextMenu(null);
      return;
    }

    const mediaStore = useMediaStore.getState();

    if (action === 'start') {
      mediaStore.generateProxy(mediaFile.id);
      console.log('[Timeline] Starting proxy generation for:', mediaFile.name);
    } else {
      mediaStore.cancelProxyGeneration(mediaFile.id);
      console.log('[Timeline] Cancelled proxy generation for:', mediaFile.name);
    }

    setContextMenu(null);
  };

  // Auto-start RAM Preview after 2 seconds of idle (like After Effects)
  const idleTimerRef = useRef<ReturnType<typeof setTimeout> | null>(null);

  // Cancel RAM preview when user starts playing or scrubbing (keep cached frames)
  useEffect(() => {
    if ((isPlaying || isDraggingPlayhead) && isRamPreviewing) {
      cancelRamPreview();
    }
  }, [isPlaying, isDraggingPlayhead, isRamPreviewing, cancelRamPreview]);

  // Check for idle state and auto-start RAM preview
  useEffect(() => {
    // Clear any existing timer
    if (idleTimerRef.current) {
      clearTimeout(idleTimerRef.current);
      idleTimerRef.current = null;
    }

    // Don't auto-render if:
    // - RAM Preview is disabled
    // - Currently playing
    // - Currently RAM previewing
    // - Scrubbing
    // - No clips on timeline
    if (!ramPreviewEnabled || isPlaying || isRamPreviewing || isDraggingPlayhead || clips.length === 0) {
      return;
    }

    // Determine render range: use In/Out if set, otherwise use clips extent
    const renderStart = inPoint ?? 0;
    const renderEnd = outPoint ?? Math.max(...clips.map(c => c.startTime + c.duration));

    // Skip if range is too small
    if (renderEnd - renderStart < 0.1) {
      return;
    }

    // Check if we already have RAM preview for this range
    if (ramPreviewRange &&
        ramPreviewRange.start <= renderStart &&
        ramPreviewRange.end >= renderEnd) {
      return;
    }

    // Start timer to auto-render after 2 seconds of idle
    idleTimerRef.current = setTimeout(() => {
      // Double-check conditions before starting
      const state = useTimelineStore.getState();
      if (state.ramPreviewEnabled && !state.isPlaying && !state.isRamPreviewing) {
        startRamPreview();
      }
    }, 2000);

    return () => {
      if (idleTimerRef.current) {
        clearTimeout(idleTimerRef.current);
        idleTimerRef.current = null;
      }
    };
  }, [ramPreviewEnabled, isPlaying, isRamPreviewing, isDraggingPlayhead, inPoint, outPoint, ramPreviewRange, clips, startRamPreview]);

  // Auto-generate proxies after 3 seconds of idle
  const proxyIdleTimerRef = useRef<ReturnType<typeof setTimeout> | null>(null);
  const { getNextFileNeedingProxy, generateProxy } = useMediaStore();

  useEffect(() => {
    // Clear any existing timer
    if (proxyIdleTimerRef.current) {
      clearTimeout(proxyIdleTimerRef.current);
      proxyIdleTimerRef.current = null;
    }

    // Don't auto-generate if:
    // - Proxy is disabled
    // - Currently playing
    // - Currently generating a proxy
    // - Scrubbing
    if (!proxyEnabled || isPlaying || currentlyGeneratingProxyId || isDraggingPlayhead) {
      return;
    }

    // Start timer to auto-generate after 3 seconds of idle
    proxyIdleTimerRef.current = setTimeout(() => {
      const mediaStore = useMediaStore.getState();
      if (mediaStore.proxyEnabled && !mediaStore.currentlyGeneratingProxyId) {
        const nextFile = mediaStore.getNextFileNeedingProxy();
        if (nextFile) {
          console.log('[Proxy] Auto-starting proxy generation for:', nextFile.name);
          mediaStore.generateProxy(nextFile.id);
        }
      }
    }, 3000);

    return () => {
      if (proxyIdleTimerRef.current) {
        clearTimeout(proxyIdleTimerRef.current);
        proxyIdleTimerRef.current = null;
      }
    };
  }, [proxyEnabled, isPlaying, currentlyGeneratingProxyId, isDraggingPlayhead, clips, getNextFileNeedingProxy, generateProxy]);

  // Track last seek time to throttle during scrubbing
  const lastSeekRef = useRef<{ [clipId: string]: number }>({});
  const pendingSeekRef = useRef<{ [clipId: string]: number }>({});
  const lastCacheTimeRef = useRef<number>(0);

  // Apply pending seeks when scrubbing stops
  useEffect(() => {
    if (isDraggingPlayhead) return;

    // Apply any pending seeks
    Object.entries(pendingSeekRef.current).forEach(([clipId, seekTime]) => {
      const clip = clips.find(c => c.id === clipId);
      if (clip?.source?.videoElement) {
        clip.source.videoElement.currentTime = seekTime;
      }
    });
    pendingSeekRef.current = {};
  }, [isDraggingPlayhead, clips]);

  // Track which clips are currently active (to detect clip changes)
  const activeClipIdsRef = useRef<string>('');

  // Track current proxy frames for each clip (for smooth proxy playback)
  const proxyFramesRef = useRef<Map<string, { frameIndex: number; image: HTMLImageElement }>>(new Map());
  const proxyLoadingRef = useRef<Set<string>>(new Set());

  // Sync timeline playback with Preview - update mixer layers based on clips at playhead
  // IMPORTANT: This uses batched updates to prevent flickering from race conditions
  useEffect(() => {
    // CRITICAL: Skip video seeking during RAM Preview generation
    if (isRamPreviewing) {
      return;
    }

    // Try to use cached RAM Preview frame first (instant playback)
    if (ramPreviewRange &&
        playheadPosition >= ramPreviewRange.start &&
        playheadPosition <= ramPreviewRange.end) {
      if (engine.renderCachedFrame(playheadPosition)) {
        return;
      }
    }

    // Get clips at playhead, considering any clip being dragged at its temporary position
    let clipsAtTime = getClipsAtTime(playheadPosition);

    // If dragging a clip, use its temporary position for preview
    if (clipDrag) {
      const draggedClipId = clipDrag.clipId;
      // Calculate temp position: use snapped time if available, otherwise calculate from pixel position
      const rawPixelX = clipDrag.currentX ?
        clipDrag.currentX - (timelineRef.current?.getBoundingClientRect().left || 0) + scrollX - clipDrag.grabOffsetX : 0;
      const tempStartTime = clipDrag.snappedTime ?? (clipDrag.currentX ?
        Math.max(0, rawPixelX / zoom) :
        null);

      if (tempStartTime !== null) {
        // Create modified clips array with dragged clip at temporary position
        const modifiedClips = clips.map(c => {
          if (c.id === draggedClipId) {
            return { ...c, startTime: tempStartTime, trackId: clipDrag.currentTrackId };
          }
          return c;
        });
        clipsAtTime = modifiedClips.filter(c =>
          playheadPosition >= c.startTime && playheadPosition < c.startTime + c.duration
        );
      }
    }

    // Get current active clip IDs to detect clip boundary crossings
    const currentActiveIds = clipsAtTime
      .filter(c => c.source?.type === 'video' || c.source?.type === 'image' || c.isComposition)
      .map(c => c.id)
      .sort()
      .join(',');

    // During playback: skip layer sync if same clips are active (fast path)
    // But MUST re-sync when clips change (clip boundaries crossed)
    // IMPORTANT: Don't skip if proxy is enabled - we need to update frames each tick
    const mediaStoreState = useMediaStore.getState();
    // Check if proxy is enabled for any video clip (ready OR generating with available frames)
    const hasActiveProxies = mediaStoreState.proxyEnabled &&
      clipsAtTime.some(clip => {
        const mediaFile = mediaStoreState.files.find(f =>
          f.id === clip.source?.mediaFileId || f.name === clip.name
        );
        return mediaFile?.proxyStatus === 'ready' ||
          (mediaFile?.proxyStatus === 'generating' && (mediaFile?.proxyProgress || 0) > 0);
      });

    if (isPlaying && !hasActiveProxies && activeClipIdsRef.current.startsWith('playing:')) {
      const prevActiveIds = activeClipIdsRef.current.slice(8); // Remove 'playing:' prefix
      if (prevActiveIds === currentActiveIds) {
        // Same clips active - skip layer sync, just ensure videos are playing
        clipsAtTime.forEach(clip => {
          if (clip.source?.videoElement?.paused) {
            clip.source.videoElement.play().catch(() => {});
          }
        });
        return;
      }
      // Clips changed - need to re-sync layers, continue below
    }

    // Update active clip tracking
    if (isPlaying) {
      clipsAtTime.forEach(clip => {
        if (clip.source?.videoElement?.paused) {
          clip.source.videoElement.play().catch(() => {});
        }
      });
      activeClipIdsRef.current = 'playing:' + currentActiveIds;
    } else {
      activeClipIdsRef.current = '';
    }

    const currentLayers = useMixerStore.getState().layers;

    // Get video tracks sorted by index (for layer order)
    const videoTracks = tracks.filter(t => t.type === 'video');

    // Check if any video track has solo enabled
    const anyVideoSolo = videoTracks.some(t => t.solo);

    // Helper to determine effective visibility for a video track
    const isVideoTrackVisible = (track: typeof videoTracks[0]) => {
      if (!track.visible) return false;
      if (anyVideoSolo) return track.solo;
      return true;
    };

    // Build new layers array atomically - don't setState inside loop!
    const newLayers = [...currentLayers];
    let layersChanged = false;

    // Helper to get video element from a clip (handles nested compositions)
    // Returns interpolated transform for keyframe animation support
    const getVideoFromClip = (clip: typeof clips[0], clipTime: number): { video: HTMLVideoElement | null; transform: typeof clip.transform } => {
      // Get interpolated transform for this clip at the current time
      const interpolatedTransform = getInterpolatedTransform(clip.id, clipTime);

      // Handle nested composition clips
      if (clip.isComposition && clip.nestedClips && clip.nestedClips.length > 0) {
        // Find active clip in nested composition at the current nested time
        const nestedTime = clipTime; // clipTime is already relative to the comp clip
        const nestedVideoTracks = (clip.nestedTracks || []).filter(t => t.type === 'video' && t.visible);

        // Find the topmost visible video clip at nestedTime
        for (const nestedTrack of nestedVideoTracks) {
          const nestedClip = clip.nestedClips.find(nc =>
            nc.trackId === nestedTrack.id &&
            nestedTime >= nc.startTime &&
            nestedTime < nc.startTime + nc.duration &&
            nc.source?.videoElement
          );

          if (nestedClip?.source?.videoElement) {
            const nestedLocalTime = nestedTime - nestedClip.startTime;
            // Handle reversed nested clips
            const nestedClipTime = nestedClip.reversed
              ? nestedClip.outPoint - nestedLocalTime
              : nestedLocalTime + nestedClip.inPoint;
            const video = nestedClip.source.videoElement;

            // Seek nested video
            const timeDiff = Math.abs(video.currentTime - nestedClipTime);
            if (timeDiff > 0.05) {
              video.currentTime = nestedClipTime;
            }

            // Control playback
            if (isPlaying && video.paused) {
              video.play().catch(() => {});
            } else if (!isPlaying && !video.paused) {
              video.pause();
            }

            return { video, transform: interpolatedTransform };
          }
        }
        return { video: null, transform: interpolatedTransform };
      }

      // Regular video clip
      return { video: clip.source?.videoElement || null, transform: interpolatedTransform };
    };

    // Process each video layer and collect updates
    videoTracks.forEach((track, layerIndex) => {
      const clip = clipsAtTime.find(c => c.trackId === track.id);
      const layer = currentLayers[layerIndex];

      // Handle composition clips with nested content
      if (clip?.isComposition && clip.nestedClips && clip.nestedClips.length > 0) {
        const clipTime = playheadPosition - clip.startTime + clip.inPoint;
        const { video, transform } = getVideoFromClip(clip, clipTime);

        if (video) {
          const needsUpdate = !layer ||
            layer.source?.videoElement !== video ||
            layer.opacity !== transform.opacity ||
            layer.blendMode !== transform.blendMode ||
            layer.position.x !== transform.position.x ||
            layer.position.y !== transform.position.y ||
            layer.scale.x !== transform.scale.x ||
            layer.scale.y !== transform.scale.y ||
            layer.rotation !== (transform.rotation.z * Math.PI / 180);

          if (needsUpdate) {
            newLayers[layerIndex] = {
              id: `timeline_layer_${layerIndex}`,
              name: clip.name,
              visible: isVideoTrackVisible(track),
              opacity: transform.opacity,
              blendMode: transform.blendMode,
              source: {
                type: 'video',
                videoElement: video,
              },
              effects: [],
              position: { x: transform.position.x, y: transform.position.y },
              scale: { x: transform.scale.x, y: transform.scale.y },
              rotation: transform.rotation.z * Math.PI / 180,
            };
            layersChanged = true;
          }
        } else {
          // Nested comp has no video at this time - clear layer
          if (layer?.source) {
            newLayers[layerIndex] = undefined as any;
            layersChanged = true;
          }
        }
      } else if (clip?.source?.videoElement) {
        // Seek video to correct position within clip
        const clipLocalTime = playheadPosition - clip.startTime; // Time relative to clip start
        // For reversed clips, also reverse keyframe time so animations play backwards
        const keyframeLocalTime = clip.reversed
          ? clip.duration - clipLocalTime
          : clipLocalTime;
        // For reversed clips, play backwards from outPoint
        const clipTime = clip.reversed
          ? clip.outPoint - clipLocalTime
          : clipLocalTime + clip.inPoint; // Time within source video (for seeking)
        const video = clip.source.videoElement;
        const webCodecsPlayer = clip.source.webCodecsPlayer;
        const timeDiff = Math.abs(video.currentTime - clipTime);

        // Check if we should use proxy frames for this clip
        const mediaStore = useMediaStore.getState();
        const mediaFile = mediaStore.files.find(f => f.name === clip.name || clip.source?.mediaFileId === f.id);
        const proxyFps = mediaFile?.proxyFps || 30;

        // Calculate if the requested frame is within generated range
        const frameIndex = Math.floor(clipTime * proxyFps);
        let useProxy = false;

        if (mediaStore.proxyEnabled && mediaFile?.proxyFps) {
          if (mediaFile.proxyStatus === 'ready') {
            // Fully ready - use proxy for all frames
            useProxy = true;
          } else if (mediaFile.proxyStatus === 'generating' && (mediaFile.proxyProgress || 0) > 0) {
            // Generating - only use proxy if the frame has been generated
            // Estimate max available frame based on progress and duration
            const totalFrames = Math.ceil((mediaFile.duration || 10) * proxyFps);
            const maxGeneratedFrame = Math.floor(totalFrames * (mediaFile.proxyProgress || 0) / 100);
            useProxy = frameIndex < maxGeneratedFrame;
          }
        }

        if (useProxy && mediaFile) {
          // Use proxy frames for DISPLAY but let video play for audio sync
          const cacheKey = `${mediaFile.id}_${clip.id}`;
          const cached = proxyFramesRef.current.get(cacheKey);

          // Let video play for audio sync - we just won't display its frames
          // Mute video since audio comes from linked audio track
          if (!video.muted) {
            video.muted = true;
          }
          if (isPlaying && video.paused) {
            video.play().catch(() => {});
          } else if (!isPlaying && !video.paused) {
            video.pause();
          }

          // Sync video position when scrubbing (not playing)
          if (!isPlaying) {
            const timeDiff = Math.abs(video.currentTime - clipTime);
            if (timeDiff > 0.1) {
              video.currentTime = clipTime;
            }
          }

          // Load proxy frame - use synchronous path if already cached in proxyFrameCache
          const loadKey = `${mediaFile.id}_${frameIndex}`;

          // Try to get frame from proxyFrameCache (might be sync if already cached)
          // Pass fps to trigger preloading of upcoming frames
          const cachedInService = proxyFrameCache.getCachedFrame(mediaFile.id, frameIndex, proxyFps);

          if (cachedInService) {
            // Frame is already in the service cache - use it immediately
            proxyFramesRef.current.set(cacheKey, { frameIndex, image: cachedInService });

            const transform = getInterpolatedTransform(clip.id, keyframeLocalTime);
            newLayers[layerIndex] = {
              id: `timeline_layer_${layerIndex}`,
              name: clip.name,
              visible: isVideoTrackVisible(track),
              opacity: transform.opacity,
              blendMode: transform.blendMode,
              source: {
                type: 'image',
                imageElement: cachedInService,
              },
              effects: [],
              position: { x: transform.position.x, y: transform.position.y },
              scale: { x: transform.scale.x, y: transform.scale.y },
              rotation: transform.rotation.z * Math.PI / 180,
            };
            layersChanged = true;
          } else if (!cached || cached.frameIndex !== frameIndex) {
            // Need to load from IndexedDB
            if (!proxyLoadingRef.current.has(loadKey)) {
              proxyLoadingRef.current.add(loadKey);

              // Capture values for closure
              const capturedLayerIndex = layerIndex;
              const capturedTransform = clip.transform;
              const capturedTrackVisible = isVideoTrackVisible(track);
              const capturedClipName = clip.name;

              proxyFrameCache.getFrame(mediaFile.id, clipTime, proxyFps).then(image => {
                proxyLoadingRef.current.delete(loadKey);
                if (image) {
                  proxyFramesRef.current.set(cacheKey, { frameIndex, image });

                  // Directly update the layer with the new frame
                  const currentLayers = useMixerStore.getState().layers;
                  const updatedLayers = [...currentLayers];
                  updatedLayers[capturedLayerIndex] = {
                    id: `timeline_layer_${capturedLayerIndex}`,
                    name: capturedClipName,
                    visible: capturedTrackVisible,
                    opacity: capturedTransform.opacity,
                    blendMode: capturedTransform.blendMode,
                    source: {
                      type: 'image',
                      imageElement: image,
                    },
                    effects: [],
                    position: { x: capturedTransform.position.x, y: capturedTransform.position.y },
                    scale: { x: capturedTransform.scale.x, y: capturedTransform.scale.y },
                    rotation: capturedTransform.rotation.z * Math.PI / 180,
                  };
                  useMixerStore.setState({ layers: updatedLayers });
                }
              });
            }

            // Use previous frame while loading (if available)
            if (cached?.image) {
              const transform = getInterpolatedTransform(clip.id, keyframeLocalTime);
              newLayers[layerIndex] = {
                id: `timeline_layer_${layerIndex}`,
                name: clip.name,
                visible: isVideoTrackVisible(track),
                opacity: transform.opacity,
                blendMode: transform.blendMode,
                source: {
                  type: 'image',
                  imageElement: cached.image,
                },
                effects: [],
                position: { x: transform.position.x, y: transform.position.y },
                scale: { x: transform.scale.x, y: transform.scale.y },
                rotation: transform.rotation.z * Math.PI / 180,
              };
              layersChanged = true;
            }
          } else if (cached?.image) {
            // Same frame as before, just use it
            const transform = getInterpolatedTransform(clip.id, keyframeLocalTime);
            const needsUpdate = !layer ||
              layer.source?.imageElement !== cached.image ||
              layer.source?.type !== 'image';

            if (needsUpdate) {
              newLayers[layerIndex] = {
                id: `timeline_layer_${layerIndex}`,
                name: clip.name,
                visible: isVideoTrackVisible(track),
                opacity: transform.opacity,
                blendMode: transform.blendMode,
                source: {
                  type: 'image',
                  imageElement: cached.image,
                },
                effects: [],
                position: { x: transform.position.x, y: transform.position.y },
                scale: { x: transform.scale.x, y: transform.scale.y },
                rotation: transform.rotation.z * Math.PI / 180,
              };
              layersChanged = true;
            }
          }
          // If proxy frame not loaded yet, keep showing the last frame (or black)
          // Do NOT fall back to video - proxy mode means proxy only
        } else {
          // Original video playback (no proxy)
          // WebCodecsPlayer (if available) listens to video element events automatically
          // We just need to seek it when scrubbing
          if (webCodecsPlayer) {
            const wcTimeDiff = Math.abs(webCodecsPlayer.currentTime - clipTime);
            if (wcTimeDiff > 0.05) {
              webCodecsPlayer.seek(clipTime);
            }
          }

          // Control HTMLVideoElement playback
          // For reversed clips, keep video paused and seek frame-by-frame
          if (clip.reversed) {
            // Always keep paused for reversed playback
            if (!video.paused) {
              video.pause();
            }
            // Always seek for reversed clips (during playback or scrubbing)
            const seekThreshold = isDraggingPlayhead ? 0.1 : 0.03;
            if (timeDiff > seekThreshold) {
              const now = performance.now();
              const lastSeek = lastSeekRef.current[clip.id] || 0;
              // Throttle seeks to ~30fps for smooth reverse playback
              if (now - lastSeek > 33) {
                video.currentTime = clipTime;
                lastSeekRef.current[clip.id] = now;
              }
            }
          } else {
            // Normal forward playback
            if (isPlaying && video.paused) {
              video.play().catch(() => {});
            } else if (!isPlaying && !video.paused) {
              video.pause();
            }

            // During playback: DON'T seek - let video play naturally, we sync FROM it
            // Only seek when scrubbing or paused
            if (!isPlaying) {
              const seekThreshold = isDraggingPlayhead ? 0.1 : 0.05;

              if (timeDiff > seekThreshold) {
                const now = performance.now();
                const lastSeek = lastSeekRef.current[clip.id] || 0;

                // Throttle seeks during scrubbing
                if (isDraggingPlayhead && now - lastSeek < 80) {
                  pendingSeekRef.current[clip.id] = clipTime;
                } else {
                  if (isDraggingPlayhead && 'fastSeek' in video) {
                    video.fastSeek(clipTime);
                  } else {
                    video.currentTime = clipTime;
                  }
                  lastSeekRef.current[clip.id] = now;
                  delete pendingSeekRef.current[clip.id];
                }
              }
            }
          }

          // Check if layer needs update
          const transform = getInterpolatedTransform(clip.id, keyframeLocalTime);
          const needsUpdate = !layer ||
            layer.source?.videoElement !== video ||
            layer.source?.webCodecsPlayer !== webCodecsPlayer ||
            layer.opacity !== transform.opacity ||
            layer.blendMode !== transform.blendMode ||
            layer.position.x !== transform.position.x ||
            layer.position.y !== transform.position.y ||
            layer.scale.x !== transform.scale.x ||
            layer.scale.y !== transform.scale.y ||
            layer.rotation !== (transform.rotation.z * Math.PI / 180);

          if (needsUpdate) {
            newLayers[layerIndex] = {
              id: `timeline_layer_${layerIndex}`,
              name: clip.name,
              visible: isVideoTrackVisible(track),
              opacity: transform.opacity,
              blendMode: transform.blendMode,
              source: {
                type: 'video',
                videoElement: video,
                webCodecsPlayer: webCodecsPlayer,
              },
              effects: [],
              position: { x: transform.position.x, y: transform.position.y },
              scale: { x: transform.scale.x, y: transform.scale.y },
              rotation: transform.rotation.z * Math.PI / 180,
            };
            layersChanged = true;
          }
        }
      } else if (clip?.source?.imageElement) {
        // Handle image clips
        const img = clip.source.imageElement;
        const imageClipLocalTime = playheadPosition - clip.startTime;
        const transform = getInterpolatedTransform(clip.id, imageClipLocalTime);
        const needsUpdate = !layer ||
          layer.source?.imageElement !== img ||
          layer.opacity !== transform.opacity ||
          layer.blendMode !== transform.blendMode ||
          layer.position.x !== transform.position.x ||
          layer.position.y !== transform.position.y ||
          layer.scale.x !== transform.scale.x ||
          layer.scale.y !== transform.scale.y ||
          layer.rotation !== (transform.rotation.z * Math.PI / 180);

        if (needsUpdate) {
          newLayers[layerIndex] = {
            id: `timeline_layer_${layerIndex}`,
            name: clip.name,
            visible: isVideoTrackVisible(track),
            opacity: transform.opacity,
            blendMode: transform.blendMode,
            source: {
              type: 'image',
              imageElement: img,
            },
            effects: [],
            position: { x: transform.position.x, y: transform.position.y },
            scale: { x: transform.scale.x, y: transform.scale.y },
            rotation: transform.rotation.z * Math.PI / 180,
          };
          layersChanged = true;
        }
      } else {
        // No clip at this position - clear the layer
        if (layer?.source) {
          newLayers[layerIndex] = undefined as any;
          layersChanged = true;
        }
      }
    });

    // Single atomic update for all layer changes - prevents flickering!
    if (layersChanged) {
      useMixerStore.setState({ layers: newLayers });
    }

    // Handle audio tracks - sync audio elements with playhead
    const audioTracks = tracks.filter(t => t.type === 'audio');

    // Check if any audio track has solo enabled
    const anyAudioSolo = audioTracks.some(t => t.solo);

    // Helper to determine if an audio track should be muted (considering solo)
    const isAudioTrackMuted = (track: typeof audioTracks[0]) => {
      if (track.muted) return true;
      if (anyAudioSolo) return !track.solo;
      return false;
    };

    audioTracks.forEach((track) => {
      const clip = clipsAtTime.find(c => c.trackId === track.id);

      if (clip?.source?.audioElement) {
        const audio = clip.source.audioElement;
        const clipTime = playheadPosition - clip.startTime + clip.inPoint;
        const timeDiff = Math.abs(audio.currentTime - clipTime);

        // Sync audio position if out of sync (but not while scrubbing to avoid choppy audio)
        if (timeDiff > 0.1 && !isDraggingPlayhead) {
          audio.currentTime = clipTime;
        }

        // Handle mute state (including solo logic)
        const effectivelyMuted = isAudioTrackMuted(track);
        audio.muted = effectivelyMuted;

        // Play/pause audio based on timeline state (pause while scrubbing)
        const shouldPlay = isPlaying && !effectivelyMuted && !isDraggingPlayhead;
        if (shouldPlay && audio.paused) {
          audio.play().catch(() => {});
        } else if (!shouldPlay && !audio.paused) {
          audio.pause();
        }
      }
    });

    // Also pause audio from clips that are no longer at playhead
    clips.forEach(clip => {
      if (clip.source?.audioElement) {
        const isAtPlayhead = clipsAtTime.some(c => c.id === clip.id);
        if (!isAtPlayhead && !clip.source.audioElement.paused) {
          clip.source.audioElement.pause();
        }
      }
    });
  }, [playheadPosition, clips, tracks, isPlaying, isDraggingPlayhead, ramPreviewRange, isRamPreviewing, clipKeyframes, clipDrag, zoom, scrollX]);

  // Get clips at time helper
  const getClipsAtTime = useCallback((time: number) => {
    return clips.filter(c => time >= c.startTime && time < c.startTime + c.duration);
  }, [clips]);

  // Playback loop - minimal work, just update UI playhead periodically
  // Video plays independently via video.play(), we just read its time for UI
  useEffect(() => {
    if (!isPlaying) return;

    let intervalId: ReturnType<typeof setInterval>;
    let lastVideoTime = 0;

    // Find the active video clip
    const getActiveVideoClip = () => {
      const state = useTimelineStore.getState();
      const pos = state.playheadPosition;
      for (const clip of state.clips) {
        if (clip.source?.videoElement && pos >= clip.startTime && pos < clip.startTime + clip.duration) {
          return clip;
        }
      }
      return null;
    };

    // Update playhead from video time - run at low frequency (15fps) to minimize React work
    const updatePlayhead = () => {
      const state = useTimelineStore.getState();
      const { duration, inPoint, outPoint, loopPlayback, pause } = state;
      const effectiveEnd = outPoint !== null ? outPoint : duration;
      const effectiveStart = inPoint !== null ? inPoint : 0;

      const activeClip = getActiveVideoClip();
      let newPosition: number;

      if (activeClip?.source?.videoElement) {
        const video = activeClip.source.videoElement;
        newPosition = activeClip.startTime + video.currentTime - activeClip.inPoint;
        lastVideoTime = video.currentTime;
      } else {
        // Fallback - increment by interval time
        newPosition = state.playheadPosition + 0.066; // ~15fps
      }

      // Handle loop/end
      if (newPosition >= effectiveEnd) {
        if (loopPlayback) {
          newPosition = effectiveStart;
          const clip = getActiveVideoClip();
          if (clip?.source?.videoElement) {
            // For reversed clips, seek to outPoint; otherwise inPoint
            clip.source.videoElement.currentTime = clip.reversed ? clip.outPoint : clip.inPoint;
          }
        } else {
          newPosition = effectiveEnd;
          pause();
          setPlayheadPosition(newPosition);
          return;
        }
      }

      setPlayheadPosition(newPosition);
    };

    // Use setInterval instead of RAF - completely decoupled from render loop
    // 15fps is enough for smooth playhead UI movement
    intervalId = setInterval(updatePlayhead, 66);

    return () => clearInterval(intervalId);
  }, [isPlaying, setPlayheadPosition]);

  // Time to pixel conversion
  const timeToPixel = (time: number) => time * zoom;
  const pixelToTime = (pixel: number) => pixel / zoom;

  // Format time as MM:SS.ms
  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = Math.floor(seconds % 60);
    const ms = Math.floor((seconds % 1) * 100);
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}.${ms.toString().padStart(2, '0')}`;
  };

  
  
  // Handle shift+mousewheel on track header to resize height
  // Handle alt+mousewheel on track header to resize all tracks of same type
  const handleTrackHeaderWheel = (e: React.WheelEvent, trackId: string) => {
    const track = tracks.find(t => t.id === trackId);
    if (!track) return;

    if (e.altKey) {
      // Alt + mousewheel: scale all tracks of same type (video or audio)
      e.preventDefault();
      e.stopPropagation();
      const delta = e.deltaY > 0 ? -10 : 10;
      useTimelineStore.getState().scaleTracksOfType(track.type, delta);
    } else if (e.shiftKey) {
      // Shift + mousewheel: scale individual track
      e.preventDefault();
      e.stopPropagation();
      const delta = e.deltaY > 0 ? -10 : 10;
      useTimelineStore.getState().setTrackHeight(trackId, track.height + delta);
    }
  };

  // Render waveform for audio clips
  const renderWaveform = (waveform: number[], width: number, height: number) => {
    if (!waveform || waveform.length === 0) return null;
    
    const barWidth = Math.max(1, width / waveform.length);
    const bars = waveform.map((value, i) => {
      const barHeight = Math.max(2, value * (height - 8));
      return (
        <div
          key={i}
          className="waveform-bar"
          style={{
            left: i * barWidth,
            height: barHeight,
            width: Math.max(1, barWidth - 1),
          }}
        />
      );
    });
    
    return (
      <div className="waveform-container" style={{ width, height }}>
        {bars}
      </div>
    );
  };

  // Handle time ruler mousedown - jump playhead immediately and enter drag mode
  const handleRulerMouseDown = (e: React.MouseEvent) => {
    if (e.button !== 0) return;
    e.stopPropagation();
    e.preventDefault();

    // IMMEDIATELY cancel RAM preview before any seeking to prevent race condition
    if (isRamPreviewing) {
      cancelRamPreview();
    }

    // Jump playhead immediately
    const rect = e.currentTarget.getBoundingClientRect();
    const x = e.clientX - rect.left + scrollX;
    const time = pixelToTime(x);
    setPlayheadPosition(Math.max(0, Math.min(time, duration)));

    // Enter drag mode immediately
    setDraggingPlayhead(true);
  };

  // Handle playhead drag
  const handlePlayheadMouseDown = (e: React.MouseEvent) => {
    e.stopPropagation();
    // IMMEDIATELY cancel RAM preview before any seeking to prevent race condition
    if (isRamPreviewing) {
      cancelRamPreview();
    }
    setDraggingPlayhead(true);
  };

  // Handle In/Out marker drag
  const handleMarkerMouseDown = (e: React.MouseEvent, type: 'in' | 'out') => {
    e.stopPropagation();
    e.preventDefault();
    const originalTime = type === 'in' ? inPoint : outPoint;
    if (originalTime === null) return;

    setMarkerDrag({
      type,
      startX: e.clientX,
      originalTime,
    });
  };

  // Handle marker dragging
  useEffect(() => {
    if (!markerDrag) return;

    const handleMouseMove = (e: MouseEvent) => {
      if (!timelineRef.current) return;
      const rect = timelineRef.current.getBoundingClientRect();
      const x = e.clientX - rect.left + scrollX;
      const time = Math.max(0, Math.min(pixelToTime(x), duration));

      if (markerDrag.type === 'in') {
        // In point can't exceed out point
        const maxTime = outPoint !== null ? outPoint : duration;
        setInPoint(Math.min(time, maxTime));
      } else {
        // Out point can't precede in point
        const minTime = inPoint !== null ? inPoint : 0;
        setOutPoint(Math.max(time, minTime));
      }
    };

    const handleMouseUp = () => {
      setMarkerDrag(null);
    };

    window.addEventListener('mousemove', handleMouseMove);
    window.addEventListener('mouseup', handleMouseUp);
    return () => {
      window.removeEventListener('mousemove', handleMouseMove);
      window.removeEventListener('mouseup', handleMouseUp);
    };
  }, [markerDrag, scrollX, duration, inPoint, outPoint, setInPoint, setOutPoint]);

  // Get all snap target times (keyframes + clip boundaries) for snapping
  const getSnapTargetTimes = useCallback(() => {
    const snapTimes: number[] = [];
    clips.forEach(clip => {
      // Add clip start and end times
      snapTimes.push(clip.startTime);
      snapTimes.push(clip.startTime + clip.duration);

      // Add keyframe times
      const clipKeyframes = getClipKeyframes(clip.id);
      clipKeyframes.forEach(kf => {
        // Absolute time = clip start + keyframe time within clip
        const absTime = clip.startTime + kf.time;
        snapTimes.push(absTime);
      });
    });
    return snapTimes;
  }, [clips, getClipKeyframes]);

  useEffect(() => {
    if (!isDraggingPlayhead) return;

    const handleMouseMove = (e: MouseEvent) => {
      if (!timelineRef.current) return;
      const rect = timelineRef.current.getBoundingClientRect();
      const x = e.clientX - rect.left + scrollX;
      let time = pixelToTime(x);

      // Snap to keyframes and clip boundaries when Shift is held
      if (e.shiftKey) {
        const snapTimes = getSnapTargetTimes();
        const snapThreshold = pixelToTime(10); // 10 pixels snap distance

        let closestSnap: number | null = null;
        let closestDistance = Infinity;

        for (const snapTime of snapTimes) {
          const distance = Math.abs(time - snapTime);
          if (distance < closestDistance && distance < snapThreshold) {
            closestDistance = distance;
            closestSnap = snapTime;
          }
        }

        if (closestSnap !== null) {
          time = closestSnap;
        }
      }

      setPlayheadPosition(Math.max(0, Math.min(time, duration)));
    };

    const handleMouseUp = () => {
      setDraggingPlayhead(false);
    };

    window.addEventListener('mousemove', handleMouseMove);
    window.addEventListener('mouseup', handleMouseUp);
    return () => {
      window.removeEventListener('mousemove', handleMouseMove);
      window.removeEventListener('mouseup', handleMouseUp);
    };
  }, [isDraggingPlayhead, scrollX, duration, setPlayheadPosition, pixelToTime, getSnapTargetTimes]);

  // Premiere-style clip drag - mouse down on clip
  const handleClipMouseDown = (e: React.MouseEvent, clipId: string) => {
    if (e.button !== 0) return; // Only left click
    e.stopPropagation();
    e.preventDefault(); // Prevent text selection

    const clip = clips.find(c => c.id === clipId);
    if (!clip) return;

    const clipElement = e.currentTarget as HTMLElement;
    const clipRect = clipElement.getBoundingClientRect();
    const grabOffsetX = e.clientX - clipRect.left;

    selectClip(clipId);

    // Set initial drag state
    const initialDrag = {
      clipId,
      originalStartTime: clip.startTime,
      originalTrackId: clip.trackId,
      grabOffsetX,
      currentX: e.clientX,
      currentTrackId: clip.trackId,
      snappedTime: null as number | null,
      isSnapping: false,
    };
    setClipDrag(initialDrag);
    clipDragRef.current = initialDrag;

    // Add event listeners immediately
    const handleMouseMove = (moveEvent: MouseEvent) => {
      const drag = clipDragRef.current;
      if (!drag || !trackLanesRef.current || !timelineRef.current) return;

      const lanesRect = trackLanesRef.current.getBoundingClientRect();
      const mouseY = moveEvent.clientY - lanesRect.top;

      let currentY = 24;
      let newTrackId = drag.currentTrackId;
      for (const track of tracks) {
        if (mouseY >= currentY && mouseY < currentY + track.height) {
          newTrackId = track.id;
          break;
        }
        currentY += track.height;
      }

      const rect = timelineRef.current.getBoundingClientRect();
      const x = moveEvent.clientX - rect.left + scrollX - drag.grabOffsetX;
      const rawTime = Math.max(0, pixelToTime(x));
      const { startTime: snappedTime, snapped } = getSnappedPosition(drag.clipId, rawTime, newTrackId);

      const newDrag = {
        ...drag,
        currentX: moveEvent.clientX,
        currentTrackId: newTrackId,
        snappedTime: snapped ? snappedTime : null,
        isSnapping: snapped,
      };
      setClipDrag(newDrag);
      clipDragRef.current = newDrag;
    };

    const handleMouseUp = (upEvent: MouseEvent) => {
      const drag = clipDragRef.current;
      if (drag && timelineRef.current) {
        const rect = timelineRef.current.getBoundingClientRect();
        const x = upEvent.clientX - rect.left + scrollX - drag.grabOffsetX;
        const newStartTime = Math.max(0, pixelToTime(x));
        moveClip(drag.clipId, newStartTime, drag.currentTrackId);
      }
      setClipDrag(null);
      clipDragRef.current = null;
      window.removeEventListener('mousemove', handleMouseMove);
      window.removeEventListener('mouseup', handleMouseUp);
    };

    window.addEventListener('mousemove', handleMouseMove);
    window.addEventListener('mouseup', handleMouseUp);
  };

  // Handle trim start (mousedown on trim handle)
  const handleTrimStart = (e: React.MouseEvent, clipId: string, edge: 'left' | 'right') => {
    e.stopPropagation();
    e.preventDefault();

    const clip = clips.find(c => c.id === clipId);
    if (!clip) return;

    selectClip(clipId);

    const initialTrim = {
      clipId,
      edge,
      originalStartTime: clip.startTime,
      originalDuration: clip.duration,
      originalInPoint: clip.inPoint,
      originalOutPoint: clip.outPoint,
      startX: e.clientX,
      currentX: e.clientX,
      altKey: e.altKey,
    };
    setClipTrim(initialTrim);
    clipTrimRef.current = initialTrim;

    // Add event listeners immediately
    const handleMouseMove = (moveEvent: MouseEvent) => {
      const newTrim = clipTrimRef.current;
      if (!newTrim) return;
      const updated = { ...newTrim, currentX: moveEvent.clientX, altKey: moveEvent.altKey };
      setClipTrim(updated);
      clipTrimRef.current = updated;
    };

    const handleMouseUp = () => {
      const trim = clipTrimRef.current;
      if (!trim) {
        setClipTrim(null);
        clipTrimRef.current = null;
        window.removeEventListener('mousemove', handleMouseMove);
        window.removeEventListener('mouseup', handleMouseUp);
        return;
      }

      const clipToTrim = clips.find(c => c.id === trim.clipId);
      if (!clipToTrim) {
        setClipTrim(null);
        clipTrimRef.current = null;
        window.removeEventListener('mousemove', handleMouseMove);
        window.removeEventListener('mouseup', handleMouseUp);
        return;
      }

      // Calculate the delta in time
      const deltaX = trim.currentX - trim.startX;
      const deltaTime = pixelToTime(deltaX);

      // Get source duration limit
      const maxDuration = clipToTrim.source?.naturalDuration || clipToTrim.duration;

      let newStartTime = trim.originalStartTime;
      let newInPoint = trim.originalInPoint;
      let newOutPoint = trim.originalOutPoint;

      if (trim.edge === 'left') {
        const maxTrim = trim.originalDuration - 0.1;
        const minTrim = -trim.originalInPoint;
        const clampedDelta = Math.max(minTrim, Math.min(maxTrim, deltaTime));
        newStartTime = trim.originalStartTime + clampedDelta;
        newInPoint = trim.originalInPoint + clampedDelta;
      } else {
        const maxExtend = maxDuration - trim.originalOutPoint;
        const minTrim = -(trim.originalDuration - 0.1);
        const clampedDelta = Math.max(minTrim, Math.min(maxExtend, deltaTime));
        newOutPoint = trim.originalOutPoint + clampedDelta;
      }

      trimClip(clipToTrim.id, newInPoint, newOutPoint);
      if (trim.edge === 'left') {
        moveClip(clipToTrim.id, Math.max(0, newStartTime), clipToTrim.trackId, trim.altKey);
      }

      if (!trim.altKey && clipToTrim.linkedClipId) {
        const linkedClip = clips.find(c => c.id === clipToTrim.linkedClipId);
        if (linkedClip) {
          const linkedMaxDuration = linkedClip.source?.naturalDuration || linkedClip.duration;
          if (trim.edge === 'left') {
            const linkedNewInPoint = Math.max(0, Math.min(linkedMaxDuration - 0.1, newInPoint));
            trimClip(linkedClip.id, linkedNewInPoint, linkedClip.outPoint);
            moveClip(linkedClip.id, Math.max(0, newStartTime), linkedClip.trackId, true);
          } else {
            const linkedNewOutPoint = Math.max(0.1, Math.min(linkedMaxDuration, newOutPoint));
            trimClip(linkedClip.id, linkedClip.inPoint, linkedNewOutPoint);
          }
        }
      }

      setClipTrim(null);
      clipTrimRef.current = null;
      window.removeEventListener('mousemove', handleMouseMove);
      window.removeEventListener('mouseup', handleMouseUp);
    };

    window.addEventListener('mousemove', handleMouseMove);
    window.addEventListener('mouseup', handleMouseUp);
  };

  // Quick duration check for dragged video files
  const getVideoDurationQuick = async (file: File): Promise<number | null> => {
    if (!file.type.startsWith('video/')) return null;

    return new Promise((resolve) => {
      const video = document.createElement('video');
      video.preload = 'metadata';

      const cleanup = () => {
        URL.revokeObjectURL(video.src);
        video.remove();
      };

      video.onloadedmetadata = () => {
        const duration = video.duration;
        cleanup();
        resolve(isFinite(duration) ? duration : null);
      };

      video.onerror = () => {
        cleanup();
        resolve(null);
      };

      // Timeout after 500ms - we want this to be fast
      setTimeout(() => {
        cleanup();
        resolve(null);
      }, 500);

      video.src = URL.createObjectURL(file);
    });
  };

  // Handle external file drag enter on track
  const handleTrackDragEnter = (e: React.DragEvent, trackId: string) => {
    e.preventDefault();
    dragCounterRef.current++;

    const rect = e.currentTarget.getBoundingClientRect();
    const x = e.clientX - rect.left + scrollX;
    const startTime = pixelToTime(x);

    // Check if dragging composition from MediaPanel
    if (e.dataTransfer.types.includes('application/x-composition-id')) {
      setExternalDrag({ trackId, startTime, x: e.clientX, y: e.clientY, duration: 5, isVideo: true });
      return;
    }

    // Check if dragging media file from MediaPanel
    if (e.dataTransfer.types.includes('application/x-media-file-id')) {
      // We can't access the data during dragenter, but we can show a preview
      // The actual mediaFileId will be read on drop
      setExternalDrag({ trackId, startTime, x: e.clientX, y: e.clientY, duration: 5, isVideo: true });
      return;
    }

    // Show preview for external files
    if (e.dataTransfer.types.includes('Files')) {
      // Check cache first for duration - find the file item (not always at index 0)
      let duration: number | undefined;
      const items = e.dataTransfer.items;
      if (items && items.length > 0) {
        // Find the file item in the list
        for (let i = 0; i < items.length; i++) {
          const item = items[i];
          if (item.kind === 'file') {
            const file = item.getAsFile();
            if (file && file.type.startsWith('video/')) {
              const cacheKey = `${file.name}_${file.size}`;
              if (dragDurationCacheRef.current?.url === cacheKey) {
                // Use cached duration
                duration = dragDurationCacheRef.current.duration;
              } else {
                // Load duration in background, update state when ready
                getVideoDurationQuick(file).then(dur => {
                  if (dur) {
                    dragDurationCacheRef.current = { url: cacheKey, duration: dur };
                    // Update the externalDrag state with the loaded duration
                    setExternalDrag(prev => prev ? { ...prev, duration: dur } : null);
                  }
                });
              }
              break; // Found the file, stop searching
            }
          }
        }
      }

      setExternalDrag({ trackId, startTime, x: e.clientX, y: e.clientY, duration });
    }
  };

  // Handle external file drag over track
  const handleTrackDragOver = (e: React.DragEvent, trackId: string) => {
    e.preventDefault();
    e.dataTransfer.dropEffect = 'copy';

    // Check if dragging from MediaPanel or external files
    const isCompDrag = e.dataTransfer.types.includes('application/x-composition-id');
    const isMediaPanelDrag = e.dataTransfer.types.includes('application/x-media-file-id');
    const isFileDrag = e.dataTransfer.types.includes('Files');

    // Update preview position
    if ((isCompDrag || isMediaPanelDrag || isFileDrag) && timelineRef.current) {
      const rect = timelineRef.current.getBoundingClientRect();
      const x = e.clientX - rect.left + scrollX;
      const startTime = pixelToTime(x);

      // Check if dragging to a video track - if so, find available audio track for preview
      const targetTrack = tracks.find(t => t.id === trackId);
      const isVideoTrack = targetTrack?.type === 'video';

      // Use cached duration from state, ref cache, or fallback to 5 seconds
      const previewDuration = externalDrag?.duration ?? dragDurationCacheRef.current?.duration ?? 5;

      // For video tracks, find an available audio track for the linked audio clip preview
      let audioTrackId: string | undefined;
      if (isVideoTrack) {
        const audioTracks = tracks.filter(t => t.type === 'audio');
        const endTime = startTime + previewDuration;

        // Find first available audio track
        for (const aTrack of audioTracks) {
          const trackClips = clips.filter(c => c.trackId === aTrack.id);
          const hasOverlap = trackClips.some(clip => {
            const clipEnd = clip.startTime + clip.duration;
            return !(endTime <= clip.startTime || startTime >= clipEnd);
          });
          if (!hasOverlap) {
            audioTrackId = aTrack.id;
            break;
          }
        }
        // If no available track, show on a "new track" area (we'll indicate this)
        if (!audioTrackId) {
          audioTrackId = '__new_audio_track__';
        }
      }

      setExternalDrag(prev => ({
        trackId,
        startTime,
        x: e.clientX,
        y: e.clientY,
        audioTrackId,
        isVideo: isVideoTrack,
        duration: prev?.duration ?? dragDurationCacheRef.current?.duration  // Keep cached duration
      }));
    }
  };

  // Handle external file drag leave
  const handleTrackDragLeave = (e: React.DragEvent) => {
    e.preventDefault();
    dragCounterRef.current--;

    if (dragCounterRef.current === 0) {
      setExternalDrag(null);
    }
  };

  // Handle external file drop on track
  const handleTrackDrop = (e: React.DragEvent, trackId: string) => {
    e.preventDefault();

    // Get cached duration before clearing state
    const cachedDuration = externalDrag?.duration ?? dragDurationCacheRef.current?.duration;

    dragCounterRef.current = 0;
    setExternalDrag(null);

    // Check for composition from MediaPanel
    const compositionId = e.dataTransfer.getData('application/x-composition-id');
    if (compositionId) {
      const mediaStore = useMediaStore.getState();
      const comp = mediaStore.compositions.find(c => c.id === compositionId);
      if (comp) {
        const rect = e.currentTarget.getBoundingClientRect();
        const x = e.clientX - rect.left + scrollX;
        const startTime = pixelToTime(x);
        // Add composition as a clip (uses composition duration)
        addCompClip(trackId, comp, Math.max(0, startTime));
        return;
      }
    }

    // Check for media file from MediaPanel
    const mediaFileId = e.dataTransfer.getData('application/x-media-file-id');
    if (mediaFileId) {
      // Look up file from media store
      const mediaStore = useMediaStore.getState();
      const mediaFile = mediaStore.files.find(f => f.id === mediaFileId);
      if (mediaFile?.file) {
        const rect = e.currentTarget.getBoundingClientRect();
        const x = e.clientX - rect.left + scrollX;
        const startTime = pixelToTime(x);
        // Pass mediaFileId for proxy frame lookup
        addClip(trackId, mediaFile.file, Math.max(0, startTime), mediaFile.duration, mediaFileId);
        return;
      }
    }

    // Check for external file drop (from file explorer)
    if (e.dataTransfer.files.length > 0) {
      const file = e.dataTransfer.files[0];
      if (file.type.startsWith('video/') || file.type.startsWith('audio/') || file.type.startsWith('image/')) {
        const rect = e.currentTarget.getBoundingClientRect();
        const x = e.clientX - rect.left + scrollX;
        const startTime = pixelToTime(x);
        addClip(trackId, file, Math.max(0, startTime), cachedDuration);
      }
    }
  };

  // Zoom with mouse wheel (Ctrl or Alt)
  const handleWheel = (e: React.WheelEvent) => {
    if (e.ctrlKey || e.altKey) {
      // Ctrl + mousewheel OR Alt + mousewheel: zoom timeline view
      e.preventDefault();
      const delta = e.deltaY > 0 ? -5 : 5;
      setZoom(zoom + delta);
    } else {
      setScrollX(scrollX + e.deltaX);
    }
  };

  // Render time ruler
  const renderTimeRuler = () => {
    const width = timeToPixel(duration);
    const markers: React.ReactElement[] = [];

    // Calculate marker interval based on zoom
    let interval = 1; // 1 second
    if (zoom < 20) interval = 5;
    if (zoom < 10) interval = 10;
    if (zoom > 100) interval = 0.5;

    for (let t = 0; t <= duration; t += interval) {
      const x = timeToPixel(t);
      const isMainMarker = t % (interval * 2) === 0 || interval >= 5;

      markers.push(
        <div
          key={t}
          className={`time-marker ${isMainMarker ? 'main' : 'sub'}`}
          style={{ left: x }}
        >
          {isMainMarker && <span className="time-label">{formatTime(t)}</span>}
        </div>
      );
    }

    return (
      <div
        className="time-ruler"
        style={{ width }}
        onMouseDown={handleRulerMouseDown}
      >
        {markers}
      </div>
    );
  };

  // Render keyframe diamonds for a property in track-level timeline
  // Position is based on absolute timeline position (clip.startTime + keyframe.time)
  const renderTrackKeyframeDiamonds = (trackId: string, property: AnimatableProperty) => {
    // Get all clips on this track
    const trackClips = clips.filter(c => c.trackId === trackId);

    // Collect all keyframes from all clips with their absolute positions
    const allKeyframes: Array<{kf: ReturnType<typeof getClipKeyframes>[0], clip: typeof clips[0], absTime: number}> = [];

    trackClips.forEach(clip => {
      const clipKeyframes = getClipKeyframes(clip.id).filter(k => k.property === property);
      clipKeyframes.forEach(kf => {
        allKeyframes.push({
          kf,
          clip,
          absTime: clip.startTime + kf.time
        });
      });
    });

    return allKeyframes.map(({ kf, absTime }) => {
      const xPos = timeToPixel(absTime);
      const isSelected = selectedKeyframeIds.has(kf.id);

      return (
        <div
          key={kf.id}
          className={`keyframe-diamond ${isSelected ? 'selected' : ''}`}
          style={{ left: `${xPos}px` }}
          onClick={(e) => {
            e.stopPropagation();
            selectKeyframe(kf.id, e.shiftKey);
          }}
          title={`${property}: ${kf.value.toFixed(3)} @ ${absTime.toFixed(2)}s (${kf.easing})`}
        />
      );
    });
  };

  // Render property labels for track header (left column)
  const renderTrackPropertyLabels = (trackId: string) => {
    return (
      <div className="track-property-labels">
        {/* Opacity - wrap in group like others for consistent borders */}
        <div className="property-label-group">
          <div className="property-group-header" style={{ cursor: 'default' }}>
            <span className="property-group-arrow" style={{ visibility: 'hidden' }}></span>
            <span>Opacity</span>
          </div>
        </div>

        {/* Position group */}
        <div className="property-label-group">
          <div
            className="property-group-header"
            onClick={(e) => {
              e.stopPropagation();
              toggleTrackPropertyGroupExpanded(trackId, 'position');
            }}
          >
            <span className={`property-group-arrow ${isTrackPropertyGroupExpanded(trackId, 'position') ? 'expanded' : ''}`}></span>
            <span>Position</span>
          </div>
          {isTrackPropertyGroupExpanded(trackId, 'position') && (
            <>
              <div className="property-label-row sub"><span className="property-label">X</span></div>
              <div className="property-label-row sub"><span className="property-label">Y</span></div>
              <div className="property-label-row sub"><span className="property-label">Z</span></div>
            </>
          )}
        </div>

        {/* Scale group */}
        <div className="property-label-group">
          <div
            className="property-group-header"
            onClick={(e) => {
              e.stopPropagation();
              toggleTrackPropertyGroupExpanded(trackId, 'scale');
            }}
          >
            <span className={`property-group-arrow ${isTrackPropertyGroupExpanded(trackId, 'scale') ? 'expanded' : ''}`}></span>
            <span>Scale</span>
          </div>
          {isTrackPropertyGroupExpanded(trackId, 'scale') && (
            <>
              <div className="property-label-row sub"><span className="property-label">X</span></div>
              <div className="property-label-row sub"><span className="property-label">Y</span></div>
            </>
          )}
        </div>

        {/* Rotation group */}
        <div className="property-label-group">
          <div
            className="property-group-header"
            onClick={(e) => {
              e.stopPropagation();
              toggleTrackPropertyGroupExpanded(trackId, 'rotation');
            }}
          >
            <span className={`property-group-arrow ${isTrackPropertyGroupExpanded(trackId, 'rotation') ? 'expanded' : ''}`}></span>
            <span>Rotation</span>
          </div>
          {isTrackPropertyGroupExpanded(trackId, 'rotation') && (
            <>
              <div className="property-label-row sub"><span className="property-label">X</span></div>
              <div className="property-label-row sub"><span className="property-label">Y</span></div>
              <div className="property-label-row sub"><span className="property-label">Z</span></div>
            </>
          )}
        </div>
      </div>
    );
  };

  // Render keyframe tracks for timeline area (right column)
  const renderTrackPropertyTracks = (trackId: string) => {
    return (
      <div className="track-property-tracks">
        {/* Opacity - wrap in group like others for consistent borders */}
        <div className="keyframe-track-group">
          <div className="keyframe-track-row group-header">
            <div className="keyframe-track">
              <div className="keyframe-track-line" />
              {renderTrackKeyframeDiamonds(trackId, 'opacity')}
            </div>
          </div>
        </div>

        {/* Position group tracks */}
        <div className="keyframe-track-group">
          <div className="keyframe-track-row group-header" />
          {isTrackPropertyGroupExpanded(trackId, 'position') && (
            <>
              <div className="keyframe-track-row">
                <div className="keyframe-track">
                  <div className="keyframe-track-line" />
                  {renderTrackKeyframeDiamonds(trackId, 'position.x')}
                </div>
              </div>
              <div className="keyframe-track-row">
                <div className="keyframe-track">
                  <div className="keyframe-track-line" />
                  {renderTrackKeyframeDiamonds(trackId, 'position.y')}
                </div>
              </div>
              <div className="keyframe-track-row">
                <div className="keyframe-track">
                  <div className="keyframe-track-line" />
                  {renderTrackKeyframeDiamonds(trackId, 'position.z')}
                </div>
              </div>
            </>
          )}
        </div>

        {/* Scale group tracks */}
        <div className="keyframe-track-group">
          <div className="keyframe-track-row group-header" />
          {isTrackPropertyGroupExpanded(trackId, 'scale') && (
            <>
              <div className="keyframe-track-row">
                <div className="keyframe-track">
                  <div className="keyframe-track-line" />
                  {renderTrackKeyframeDiamonds(trackId, 'scale.x')}
                </div>
              </div>
              <div className="keyframe-track-row">
                <div className="keyframe-track">
                  <div className="keyframe-track-line" />
                  {renderTrackKeyframeDiamonds(trackId, 'scale.y')}
                </div>
              </div>
            </>
          )}
        </div>

        {/* Rotation group tracks */}
        <div className="keyframe-track-group">
          <div className="keyframe-track-row group-header" />
          {isTrackPropertyGroupExpanded(trackId, 'rotation') && (
            <>
              <div className="keyframe-track-row">
                <div className="keyframe-track">
                  <div className="keyframe-track-line" />
                  {renderTrackKeyframeDiamonds(trackId, 'rotation.x')}
                </div>
              </div>
              <div className="keyframe-track-row">
                <div className="keyframe-track">
                  <div className="keyframe-track-line" />
                  {renderTrackKeyframeDiamonds(trackId, 'rotation.y')}
                </div>
              </div>
              <div className="keyframe-track-row">
                <div className="keyframe-track">
                  <div className="keyframe-track-line" />
                  {renderTrackKeyframeDiamonds(trackId, 'rotation.z')}
                </div>
              </div>
            </>
          )}
        </div>
      </div>
    );
  };

  // Render a clip - now with Premiere-style direct dragging and trimming
  const renderClip = (clip: typeof clips[0], trackId: string) => {
    const isSelected = selectedClipId === clip.id;
    const isDragging = clipDrag?.clipId === clip.id;
    const isTrimming = clipTrim?.clipId === clip.id;
    const thumbnails = clip.thumbnails || [];

    // Get proxy status for this clip's media file
    const mediaStore = useMediaStore.getState();
    // Look up by mediaFileId first (most reliable), then by name
    const mediaFile = mediaStore.files.find(f =>
      f.id === clip.source?.mediaFileId ||
      f.name === clip.name ||
      f.name === clip.name.replace(' (Audio)', '')
    );
    const proxyProgress = mediaFile?.proxyProgress || 0;
    const proxyStatus = mediaFile?.proxyStatus;
    const isGeneratingProxy = proxyStatus === 'generating';
    const hasProxy = proxyStatus === 'ready';

    // Check if this clip is linked to the dragging/trimming clip
    const draggedClip = clipDrag ? clips.find(c => c.id === clipDrag.clipId) : null;
    const trimmedClip = clipTrim ? clips.find(c => c.id === clipTrim.clipId) : null;
    const isLinkedToDragging = clipDrag && draggedClip && (
      clip.linkedClipId === clipDrag.clipId ||
      draggedClip.linkedClipId === clip.id
    );
    const isLinkedToTrimming = clipTrim && !clipTrim.altKey && trimmedClip && (
      clip.linkedClipId === clipTrim.clipId ||
      trimmedClip.linkedClipId === clip.id
    );

    // Calculate live trim values
    let displayStartTime = clip.startTime;
    let displayDuration = clip.duration;

    if (isTrimming && clipTrim) {
      const deltaX = clipTrim.currentX - clipTrim.startX;
      const deltaTime = pixelToTime(deltaX);
      const maxDuration = clip.source?.naturalDuration || clip.duration;

      if (clipTrim.edge === 'left') {
        const maxTrim = clipTrim.originalDuration - 0.1;
        const minTrim = -clipTrim.originalInPoint;
        const clampedDelta = Math.max(minTrim, Math.min(maxTrim, deltaTime));
        displayStartTime = clipTrim.originalStartTime + clampedDelta;
        displayDuration = clipTrim.originalDuration - clampedDelta;
      } else {
        const maxExtend = maxDuration - clipTrim.originalOutPoint;
        const minTrim = -(clipTrim.originalDuration - 0.1);
        const clampedDelta = Math.max(minTrim, Math.min(maxExtend, deltaTime));
        displayDuration = clipTrim.originalDuration + clampedDelta;
      }
    } else if (isLinkedToTrimming && clipTrim && trimmedClip) {
      // Apply same trim to linked clip visually
      const deltaX = clipTrim.currentX - clipTrim.startX;
      const deltaTime = pixelToTime(deltaX);
      const maxDuration = clip.source?.naturalDuration || clip.duration;

      if (clipTrim.edge === 'left') {
        const maxTrim = clip.duration - 0.1;
        const minTrim = -clip.inPoint;
        const clampedDelta = Math.max(minTrim, Math.min(maxTrim, deltaTime));
        displayStartTime = clip.startTime + clampedDelta;
        displayDuration = clip.duration - clampedDelta;
      } else {
        const maxExtend = maxDuration - clip.outPoint;
        const minTrim = -(clip.duration - 0.1);
        const clampedDelta = Math.max(minTrim, Math.min(maxExtend, deltaTime));
        displayDuration = clip.duration + clampedDelta;
      }
    }

    const width = timeToPixel(displayDuration);

    // Calculate position - if dragging, use snapped position if available
    let left = timeToPixel(displayStartTime);
    if (isDragging && clipDrag && timelineRef.current) {
      // Use snapped time if snapping, otherwise raw position
      if (clipDrag.isSnapping && clipDrag.snappedTime !== null) {
        left = timeToPixel(clipDrag.snappedTime);
      } else {
        const rect = timelineRef.current.getBoundingClientRect();
        const x = clipDrag.currentX - rect.left + scrollX - clipDrag.grabOffsetX;
        left = Math.max(0, x);
      }
    } else if (isLinkedToDragging && clipDrag && timelineRef.current && draggedClip) {
      // Move linked clip in sync - use snapped position if available
      let newDragTime: number;
      if (clipDrag.isSnapping && clipDrag.snappedTime !== null) {
        newDragTime = clipDrag.snappedTime;
      } else {
        const rect = timelineRef.current.getBoundingClientRect();
        const dragX = clipDrag.currentX - rect.left + scrollX - clipDrag.grabOffsetX;
        newDragTime = pixelToTime(Math.max(0, dragX));
      }
      const timeDelta = newDragTime - draggedClip.startTime;
      left = timeToPixel(Math.max(0, clip.startTime + timeDelta));
    }

    // Calculate how many thumbnails to show based on clip width
    const thumbWidth = 71;
    const visibleThumbs = Math.max(1, Math.ceil(width / thumbWidth));

    // Track filtering
    if (isDragging && clipDrag && clipDrag.currentTrackId !== trackId) {
      return null;
    }
    if (!isDragging && !isLinkedToDragging && clip.trackId !== trackId) {
      return null;
    }
    if (clip.trackId !== trackId && !isDragging) {
      return null;
    }

    const clipClass = [
      'timeline-clip',
      isSelected ? 'selected' : '',
      isDragging ? 'dragging' : '',
      isLinkedToDragging ? 'linked-dragging' : '',
      isTrimming ? 'trimming' : '',
      isLinkedToTrimming ? 'linked-trimming' : '',
      clip.source?.type || 'video',
      clip.isLoading ? 'loading' : '',
      hasProxy ? 'has-proxy' : '',
      isGeneratingProxy ? 'generating-proxy' : '',
      hasKeyframes(clip.id) ? 'has-keyframes' : '',
      clip.reversed ? 'reversed' : ''
    ].filter(Boolean).join(' ');

    return (
      <div
        key={clip.id}
        className={clipClass}
        style={{ left, width }}
        onMouseDown={(e) => handleClipMouseDown(e, clip.id)}
        onContextMenu={(e) => handleClipContextMenu(e, clip.id)}
      >
        {/* Proxy progress bar */}
        {isGeneratingProxy && (
          <div className="clip-proxy-progress">
            <div
              className="clip-proxy-progress-bar"
              style={{ width: `${proxyProgress}%` }}
            />
          </div>
        )}
        {/* Proxy ready indicator */}
        {hasProxy && mediaStore.proxyEnabled && (
          <div className="clip-proxy-badge" title="Proxy ready">P</div>
        )}
        {/* Reversed indicator */}
        {clip.reversed && (
          <div className="clip-reversed-badge" title="Reversed playback"></div>
        )}
        {/* Audio waveform */}
        {clip.source?.type === 'audio' && clip.waveform && clip.waveform.length > 0 && (
          <div className="clip-waveform">
            {renderWaveform(clip.waveform, width, Math.max(20, (tracks.find(t => t.id === trackId)?.height || 40) - 12))}
          </div>
        )}
        {/* Thumbnail filmstrip */}
        {thumbnails.length > 0 && clip.source?.type !== 'audio' && (
          <div className="clip-thumbnails">
            {Array.from({ length: visibleThumbs }).map((_, i) => {
              const thumbIndex = Math.floor((i / visibleThumbs) * thumbnails.length);
              const thumb = thumbnails[Math.min(thumbIndex, thumbnails.length - 1)];
              return (
                <img
                  key={i}
                  src={thumb}
                  alt=""
                  className="clip-thumb"
                  draggable={false}
                />
              );
            })}
          </div>
        )}
        <div className="clip-content">
          {clip.isLoading && <div className="clip-loading-spinner" />}
          <span className="clip-name">{clip.name}</span>
          <span className="clip-duration">{formatTime(displayDuration)}</span>
        </div>
        {/* Trim handles */}
        <div
          className="trim-handle left"
          onMouseDown={(e) => handleTrimStart(e, clip.id, 'left')}
        />
        <div
          className="trim-handle right"
          onMouseDown={(e) => handleTrimStart(e, clip.id, 'right')}
        />
      </div>
    );
  };

  // No active composition - show empty state
  // Show empty state only if no tabs are open
  if (openCompositions.length === 0) {
    return (
      <div className="timeline-container timeline-empty">
        <div className="timeline-empty-message">
          <p>No composition open</p>
          <p className="hint">Double-click a composition in the Media panel to open it</p>
        </div>
      </div>
    );
  }

  return (
    <div className={`timeline-container ${clipDrag || clipTrim ? 'is-dragging' : ''}`}>
      {/* Timeline toolbar */}
      <div className="timeline-toolbar">
        <div className="timeline-controls">
          <button className="btn btn-sm" onClick={stop} title="Stop"></button>
          <button className={`btn btn-sm ${isPlaying ? 'btn-active' : ''}`} onClick={isPlaying ? pause : play}>
            {isPlaying ? '' : ''}
          </button>
          <button
            className={`btn btn-sm ${loopPlayback ? 'btn-active' : ''}`}
            onClick={toggleLoopPlayback}
            title={loopPlayback ? 'Loop On (L)' : 'Loop Off (L)'}
          >
            
          </button>
        </div>
        <div className="timeline-time">
          {formatTime(playheadPosition)} / {formatTime(duration)}
        </div>
        <div className="timeline-zoom">
          <button className="btn btn-sm" onClick={() => setZoom(zoom - 10)}></button>
          <span>{Math.round(zoom)}px/s</span>
          <button className="btn btn-sm" onClick={() => setZoom(zoom + 10)}>+</button>
        </div>
        <div className="timeline-inout-controls">
          <button
            className={`btn btn-sm ${inPoint !== null ? 'btn-active' : ''}`}
            onClick={setInPointAtPlayhead}
            title="Set In point (I)"
          >
            I
          </button>
          <button
            className={`btn btn-sm ${outPoint !== null ? 'btn-active' : ''}`}
            onClick={setOutPointAtPlayhead}
            title="Set Out point (O)"
          >
            O
          </button>
          {(inPoint !== null || outPoint !== null) && (
            <button
              className="btn btn-sm"
              onClick={clearInOut}
              title="Clear In/Out (X)"
            >
              X
            </button>
          )}
        </div>
        <div className="timeline-ram-preview">
          <button
            className={`btn btn-sm ${ramPreviewEnabled ? 'btn-active' : ''}`}
            onClick={toggleRamPreviewEnabled}
            title={ramPreviewEnabled
              ? "RAM Preview ON - Auto-caches frames for instant scrubbing. Click to disable and clear cache."
              : "RAM Preview OFF - Click to enable auto-caching for instant scrubbing"}
          >
            RAM {ramPreviewEnabled ? 'ON' : 'OFF'}
          </button>
          <button
            className={`btn btn-sm ${proxyEnabled ? 'btn-active' : ''}`}
            onClick={() => setProxyEnabled(!proxyEnabled)}
            title={proxyEnabled ? 'Proxy enabled - using optimized frames' : 'Proxy disabled - using original video'}
          >
            {currentlyGeneratingProxyId ? (
              <> Generating...</>
            ) : (
              <>
                {proxyEnabled ? '' : ''} Proxy {proxyEnabled ? 'On' : 'Off'}
                {mediaFiles.filter(f => f.proxyStatus === 'ready').length > 0 && (
                  <span className="proxy-count">
                    ({mediaFiles.filter(f => f.proxyStatus === 'ready').length})
                  </span>
                )}
              </>
            )}
          </button>
        </div>
        <div className="timeline-tracks-controls">
          <button className="btn btn-sm" onClick={() => addTrack('video')}>+ Video Track</button>
          <button className="btn btn-sm" onClick={() => addTrack('audio')}>+ Audio Track</button>
        </div>
      </div>

      {/* Timeline body */}
      <div className="timeline-body">
        {/* Track headers */}
        <div className="track-headers">
          <div className="ruler-header">Time</div>
          {(() => {
            // Check if any track of each type has solo enabled
            const anyVideoSolo = tracks.some(t => t.type === 'video' && t.solo);
            const anyAudioSolo = tracks.some(t => t.type === 'audio' && t.solo);

            return tracks.map(track => {
              // Determine if this track should be dimmed (another track of same type is solo'd, but not this one)
              const isDimmed = (track.type === 'video' && anyVideoSolo && !track.solo) ||
                               (track.type === 'audio' && anyAudioSolo && !track.solo);

              const isExpanded = isTrackExpanded(track.id);
              const dynamicHeight = getExpandedTrackHeight(track.id, track.height);
              return (
                <div
                  key={track.id}
                  className={`track-header ${track.type} ${isDimmed ? 'dimmed' : ''} ${isExpanded ? 'expanded' : ''}`}
                  style={{ height: dynamicHeight }}
                  onWheel={(e) => handleTrackHeaderWheel(e, track.id)}
                >
                  <div className="track-header-top" style={{ height: track.height }}>
                    <div className="track-header-main">
                      {/* Only video tracks get expand arrow */}
                      {track.type === 'video' && (
                        <span
                          className={`track-expand-arrow ${isExpanded ? 'expanded' : ''} ${trackHasKeyframes(track.id) ? 'has-keyframes' : ''}`}
                          onClick={(e) => {
                            e.stopPropagation();
                            toggleTrackExpanded(track.id);
                          }}
                          title={isExpanded ? 'Collapse properties' : 'Expand properties'}
                        >
                          
                        </span>
                      )}
                      <span className="track-name">{track.name}</span>
                    </div>
                    <div className="track-controls">
                    <button
                      className={`btn-icon ${track.solo ? 'solo-active' : ''}`}
                      onClick={() => useTimelineStore.getState().setTrackSolo(track.id, !track.solo)}
                      title={track.solo ? 'Solo On' : 'Solo Off'}
                    >
                      S
                    </button>
                    {track.type === 'audio' && (
                      <button
                        className={`btn-icon ${track.muted ? 'muted' : ''}`}
                        onClick={() => useTimelineStore.getState().setTrackMuted(track.id, !track.muted)}
                        title={track.muted ? 'Unmute' : 'Mute'}
                      >
                        {track.muted ? '' : ''}
                      </button>
                    )}
                    {track.type === 'video' && (
                      <button
                        className={`btn-icon ${!track.visible ? 'hidden' : ''}`}
                        onClick={() => useTimelineStore.getState().setTrackVisible(track.id, !track.visible)}
                        title={track.visible ? 'Hide' : 'Show'}
                      >
                        {track.visible ? '' : ''}
                      </button>
                    )}
                    </div>
                  </div>
                  {/* Property labels - shown when track is expanded */}
                  {track.type === 'video' && isExpanded && renderTrackPropertyLabels(track.id)}
                </div>
              );
            });
          })()}
        </div>

        {/* Timeline tracks */}
        <div
          ref={(el) => {
            (timelineRef as React.MutableRefObject<HTMLDivElement | null>).current = el;
            (trackLanesRef as React.MutableRefObject<HTMLDivElement | null>).current = el;
          }}
          className={`timeline-tracks ${clipDrag ? 'dragging-clip' : ''}`}
          onWheel={handleWheel}
          style={{ transform: `translateX(-${scrollX}px)` }}
        >
          {/* Time ruler */}
          {renderTimeRuler()}

          {/* Track lanes */}
          {(() => {
            const anyVideoSolo = tracks.some(t => t.type === 'video' && t.solo);
            const anyAudioSolo = tracks.some(t => t.type === 'audio' && t.solo);

            return tracks.map(track => {
              const isDimmed = (track.type === 'video' && anyVideoSolo && !track.solo) ||
                               (track.type === 'audio' && anyAudioSolo && !track.solo);
              const isExpanded = isTrackExpanded(track.id);
              const dynamicHeight = getExpandedTrackHeight(track.id, track.height);
              return (
            <div
              key={track.id}
              className={`track-lane ${track.type} ${isDimmed ? 'dimmed' : ''} ${isExpanded ? 'expanded' : ''} ${clipDrag?.currentTrackId === track.id ? 'drag-target' : ''} ${externalDrag?.trackId === track.id || externalDrag?.audioTrackId === track.id ? 'external-drag-target' : ''}`}
              style={{ height: dynamicHeight }}
              onDrop={(e) => handleTrackDrop(e, track.id)}
              onDragOver={(e) => handleTrackDragOver(e, track.id)}
              onDragEnter={(e) => handleTrackDragEnter(e, track.id)}
              onDragLeave={handleTrackDragLeave}
            >
              {/* Clip row - the normal clip area */}
              <div className="track-clip-row" style={{ height: track.height }}>
                {/* Render clips belonging to this track */}
                {clips
                  .filter(c => c.trackId === track.id)
                  .map(clip => renderClip(clip, track.id))}
              {/* Render clip being dragged TO this track */}
              {clipDrag && clipDrag.currentTrackId === track.id && clipDrag.originalTrackId !== track.id && (
                clips
                  .filter(c => c.id === clipDrag.clipId)
                  .map(clip => renderClip(clip, track.id))
              )}
              {/* External file drag preview - video clip */}
              {externalDrag && externalDrag.trackId === track.id && (
                <div
                  className="timeline-clip-preview"
                  style={{
                    left: timeToPixel(externalDrag.startTime),
                    width: timeToPixel(externalDrag.duration ?? 5),
                  }}
                >
                  <div className="clip-content">
                    <span className="clip-name">Drop to add clip</span>
                  </div>
                </div>
              )}
              {/* External file drag preview - linked audio clip */}
              {externalDrag && externalDrag.isVideo && externalDrag.audioTrackId === track.id && (
                <div
                  className="timeline-clip-preview audio"
                  style={{
                    left: timeToPixel(externalDrag.startTime),
                    width: timeToPixel(externalDrag.duration ?? 5),
                  }}
                >
                  <div className="clip-content">
                    <span className="clip-name">Audio</span>
                  </div>
                </div>
              )}
              </div>
              {/* Property rows - only shown when track is expanded */}
              {track.type === 'video' && isExpanded && renderTrackPropertyTracks(track.id)}
            </div>
              );
            });
          })()}

          {/* Preview for new audio track that will be created */}
          {externalDrag && externalDrag.isVideo && externalDrag.audioTrackId === '__new_audio_track__' && (
            <div
              className="track-lane audio new-track-preview"
              style={{ height: 40 }}
            >
              <div
                className="timeline-clip-preview audio"
                style={{
                  left: timeToPixel(externalDrag.startTime),
                  width: timeToPixel(externalDrag.duration ?? 5),
                }}
              >
                <div className="clip-content">
                  <span className="clip-name">+ New Audio Track</span>
                </div>
              </div>
            </div>
          )}

          {/* Snap indicator line - shows when clip is snapping to another */}
          {clipDrag?.isSnapping && clipDrag.snappedTime !== null && (
            <div
              className="snap-line"
              style={{ left: timeToPixel(clipDrag.snappedTime) }}
            />
          )}

          {/* In/Out work area - grey out regions outside */}
          {(inPoint !== null || outPoint !== null) && (
            <>
              {/* Grey overlay before In point */}
              {inPoint !== null && inPoint > 0 && (
                <div
                  className="work-area-overlay before"
                  style={{
                    left: 0,
                    width: timeToPixel(inPoint),
                  }}
                />
              )}
              {/* Grey overlay after Out point */}
              {outPoint !== null && (
                <div
                  className="work-area-overlay after"
                  style={{
                    left: timeToPixel(outPoint),
                    width: timeToPixel(duration - outPoint),
                  }}
                />
              )}
            </>
          )}

          {/* RAM Preview progress text (during rendering) */}
          {isRamPreviewing && ramPreviewProgress !== null && (
            <div
              className="ram-preview-progress-text"
              style={{
                left: timeToPixel(playheadPosition) + 10,
              }}
            >
              {Math.round(ramPreviewProgress)}%
            </div>
          )}

          {/* Cached frames indicator (green = frames in RAM) */}
          {getCachedRanges().map((range, i) => (
            <div
              key={i}
              className="playback-cache-indicator"
              style={{
                left: timeToPixel(range.start),
                width: Math.max(2, timeToPixel(range.end - range.start)),
              }}
              title={`Cached: ${formatTime(range.start)} - ${formatTime(range.end)}`}
            />
          ))}

          {/* In point marker */}
          {inPoint !== null && (
            <div
              className={`in-out-marker in-marker ${markerDrag?.type === 'in' ? 'dragging' : ''}`}
              style={{ left: timeToPixel(inPoint) }}
              title={`In: ${formatTime(inPoint)} (drag to move)`}
            >
              <div
                className="marker-flag"
                onMouseDown={(e) => handleMarkerMouseDown(e, 'in')}
              >I</div>
              <div className="marker-line" />
            </div>
          )}

          {/* Out point marker */}
          {outPoint !== null && (
            <div
              className={`in-out-marker out-marker ${markerDrag?.type === 'out' ? 'dragging' : ''}`}
              style={{ left: timeToPixel(outPoint) }}
              title={`Out: ${formatTime(outPoint)} (drag to move)`}
            >
              <div
                className="marker-flag"
                onMouseDown={(e) => handleMarkerMouseDown(e, 'out')}
              >O</div>
              <div className="marker-line" />
            </div>
          )}

          {/* Playhead */}
          <div
            className="playhead"
            style={{ left: timeToPixel(playheadPosition) }}
            onMouseDown={handlePlayheadMouseDown}
          >
            <div className="playhead-head" />
            <div className="playhead-line" />
          </div>
        </div>
      </div>

      {/* Context Menu for clips */}
      {contextMenu && (() => {
        const mediaFile = getMediaFileForClip(contextMenu.clipId);
        const clip = clips.find(c => c.id === contextMenu.clipId);
        const isVideo = clip?.source?.type === 'video';
        const isGenerating = mediaFile?.proxyStatus === 'generating';
        const hasProxy = mediaFile?.proxyStatus === 'ready';

        return (
          <div
            className="timeline-context-menu"
            style={{
              position: 'fixed',
              left: contextMenu.x,
              top: contextMenu.y,
              zIndex: 10000,
            }}
            onClick={(e) => e.stopPropagation()}
          >
            {/* Show in Explorer submenu - only for video clips */}
            {isVideo && (
              <div className="context-menu-item has-submenu">
                <span>Show in Explorer</span>
                <span className="submenu-arrow"></span>
                <div className="context-submenu">
                  <div
                    className="context-menu-item"
                    onClick={() => handleShowInExplorer('raw')}
                  >
                    Raw {mediaFile?.hasFileHandle && '(has path)'}
                  </div>
                  <div
                    className={`context-menu-item ${!hasProxy ? 'disabled' : ''}`}
                    onClick={() => hasProxy && handleShowInExplorer('proxy')}
                  >
                    Proxy {!hasProxy ? '(not available)' : proxyFolderName ? `(${proxyFolderName})` : '(IndexedDB)'}
                  </div>
                </div>
              </div>
            )}

            {/* Proxy Generation - only for video clips */}
            {isVideo && (
              <>
                <div className="context-menu-separator" />
                {isGenerating ? (
                  <div
                    className="context-menu-item"
                    onClick={() => handleProxyGeneration('stop')}
                  >
                    Stop Proxy Generation ({mediaFile?.proxyProgress || 0}%)
                  </div>
                ) : hasProxy ? (
                  <div className="context-menu-item disabled">
                    Proxy Ready
                  </div>
                ) : (
                  <div
                    className="context-menu-item"
                    onClick={() => handleProxyGeneration('start')}
                  >
                    Generate Proxy
                  </div>
                )}

                {/* Set Proxy Folder */}
                <div
                  className="context-menu-item"
                  onClick={handleSetProxyFolder}
                >
                  Set Proxy Folder... {proxyFolderName && `(${proxyFolderName})`}
                </div>
              </>
            )}

            {/* Split clip option */}
            <div className="context-menu-separator" />
            <div
              className="context-menu-item"
              onClick={() => {
                splitClipAtPlayhead();
                setContextMenu(null);
              }}
            >
              Split at Playhead (C)
            </div>

            {/* Reverse clip option - only for video clips */}
            {isVideo && (
              <div
                className={`context-menu-item ${clip?.reversed ? 'checked' : ''}`}
                onClick={() => {
                  if (contextMenu.clipId) {
                    toggleClipReverse(contextMenu.clipId);
                  }
                  setContextMenu(null);
                }}
              >
                {clip?.reversed ? ' ' : ''}Reverse Playback
              </div>
            )}

            {/* Delete clip option */}
            <div
              className="context-menu-item danger"
              onClick={() => {
                if (contextMenu.clipId) {
                  removeClip(contextMenu.clipId);
                }
                setContextMenu(null);
              }}
            >
              Delete Clip
            </div>
          </div>
        );
      })()}
    </div>
  );
}
