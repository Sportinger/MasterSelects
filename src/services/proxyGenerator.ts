// GPU-accelerated proxy frame generator using WebCodecs + WebGPU
// Uses VideoDecoder for hardware decoding and GPU for batch resize
// Workers handle parallel WebP encoding

import { Logger } from './logger';
import * as MP4BoxModule from 'mp4box';

const log = Logger.create('ProxyGenerator');
import { engine } from '../engine/WebGPUEngine';
import { ProxyResizePipeline } from '../engine/proxy/ProxyResizePipeline';

const MP4Box = (MP4BoxModule as any).default || MP4BoxModule;

// Configuration
const PROXY_FPS = 30;
const PROXY_QUALITY = 0.92;
const PROXY_MAX_WIDTH = 1280; // Changed from 1920 for faster generation
const WORKER_POOL_SIZE = navigator.hardwareConcurrency || 4;
const BATCH_SIZE = ProxyResizePipeline.getBatchSize(); // 16 frames per GPU batch
const DB_BATCH_SIZE = 10; // IndexedDB write batch size

// MP4Box types
interface MP4ArrayBuffer extends ArrayBuffer {
  fileStart: number;
}

interface Sample {
  number: number;
  track_id: number;
  data: ArrayBuffer;
  size: number;
  cts: number;
  dts: number;
  duration: number;
  is_sync: boolean;
  timescale: number;
}

interface MP4VideoTrack {
  id: number;
  codec: string;
  duration: number;
  timescale: number;
  nb_samples: number;
  video: { width: number; height: number };
}

interface MP4File {
  onReady: (info: { videoTracks: MP4VideoTrack[] }) => void;
  onSamples: (trackId: number, ref: any, samples: Sample[]) => void;
  onError: (error: string) => void;
  appendBuffer: (buffer: MP4ArrayBuffer) => number;
  start: () => void;
  flush: () => void;
  setExtractionOptions: (trackId: number, user: any, options: { nbSamples: number }) => void;
  getTrackById: (id: number) => any;
}

interface GeneratorResult {
  frameCount: number;
  fps: number;
}

// Worker code that accepts raw RGBA pixels
const workerCode = `
  self.onmessage = async function(e) {
    const { frameIndex, pixels, width, height, quality } = e.data;

    try {
      // Validate input
      if (!pixels || pixels.byteLength === 0) {
        throw new Error('Empty pixel data');
      }

      const expectedSize = width * height * 4;
      if (pixels.byteLength !== expectedSize) {
        throw new Error('Pixel data size mismatch: got ' + pixels.byteLength + ', expected ' + expectedSize);
      }

      if (width <= 0 || height <= 0) {
        throw new Error('Invalid dimensions: ' + width + 'x' + height);
      }

      // Create ImageData from raw pixels
      const imageData = new ImageData(new Uint8ClampedArray(pixels), width, height);

      // Create OffscreenCanvas and draw ImageData
      const canvas = new OffscreenCanvas(width, height);
      const ctx = canvas.getContext('2d');
      if (!ctx) {
        throw new Error('Failed to get 2d context');
      }
      ctx.putImageData(imageData, 0, 0);

      // Encode to WebP with fallback to PNG
      let blob;
      try {
        blob = await canvas.convertToBlob({ type: 'image/webp', quality });
      } catch (webpErr) {
        // Fallback to PNG if WebP fails
        console.warn('[Worker] WebP encoding failed, trying PNG for frame ' + frameIndex);
        blob = await canvas.convertToBlob({ type: 'image/png' });
      }

      // Send back the result
      self.postMessage({ frameIndex, blob });
    } catch (err) {
      console.error('[Worker] Frame ' + frameIndex + ' encoding error:', err.message);
      // Send error back to main thread
      self.postMessage({ frameIndex, error: err.message });
    }
  };
`;

class ProxyGeneratorGPU {
  private mp4File: MP4File | null = null;
  private decoder: VideoDecoder | null = null;
  private workers: Worker[] = [];
  private workerBusy: boolean[] = [];
  private pendingFrames: Map<number, { resolve: (blob: Blob) => void; reject: (err: Error) => void }> = new Map();
  private frameQueue: { frameIndex: number; pixels: Uint8Array }[] = [];

  private videoTrack: MP4VideoTrack | null = null;
  private samples: Sample[] = [];
  private codecConfig: VideoDecoderConfig | null = null;

  // GPU resize pipeline
  private resizePipeline: ProxyResizePipeline | null = null;

  private outputWidth = 0;
  private outputHeight = 0;
  private duration = 0;
  private totalFrames = 0;
  private processedFrames = 0;
  private decodedFrames: Map<number, VideoFrame> = new Map();
  private frameTimestamps: number[] = [];

  private onProgress: ((progress: number) => void) | null = null;
  private checkCancelled: (() => boolean) | null = null;
  private isCancelled = false;

  private resolveGeneration: ((result: GeneratorResult | null) => void) | null = null;

  constructor() {
    this.initWorkers();
  }

  private initWorkers() {
    const blob = new Blob([workerCode], { type: 'application/javascript' });
    const workerUrl = URL.createObjectURL(blob);

    for (let i = 0; i < WORKER_POOL_SIZE; i++) {
      const worker = new Worker(workerUrl);
      worker.onmessage = (e) => this.handleWorkerMessage(i, e.data);
      worker.onerror = (e) => log.error('Worker error', e);
      this.workers.push(worker);
      this.workerBusy.push(false);
    }

    log.info(`Initialized ${WORKER_POOL_SIZE} encoding workers`);
  }

  private handleWorkerMessage(workerIndex: number, data: { frameIndex: number; blob?: Blob; error?: string }) {
    this.workerBusy[workerIndex] = false;

    const pending = this.pendingFrames.get(data.frameIndex);
    if (pending) {
      if (data.error) {
        // Log error but don't reject - just skip this frame
        log.warn(`Worker failed to encode frame ${data.frameIndex}: ${data.error}`);
        // Create a tiny placeholder blob
        pending.resolve(new Blob([], { type: 'image/webp' }));
      } else if (data.blob) {
        pending.resolve(data.blob);
      } else {
        log.warn(`Worker returned no data for frame ${data.frameIndex}`);
        pending.resolve(new Blob([], { type: 'image/webp' }));
      }
      this.pendingFrames.delete(data.frameIndex);
    }

    // Process next frame in queue
    this.processFrameQueue();
  }

  private processFrameQueue() {
    if (this.frameQueue.length === 0) return;

    // Find an available worker
    const workerIndex = this.workerBusy.findIndex(busy => !busy);
    if (workerIndex === -1) return;

    const frame = this.frameQueue.shift()!;
    this.workerBusy[workerIndex] = true;

    this.workers[workerIndex].postMessage({
      frameIndex: frame.frameIndex,
      pixels: frame.pixels,
      width: this.outputWidth,
      height: this.outputHeight,
      quality: PROXY_QUALITY,
    }, [frame.pixels.buffer]); // Transfer buffer for performance
  }

  private encodeFrameAsync(frameIndex: number, pixels: Uint8Array): Promise<Blob> {
    return new Promise((resolve, reject) => {
      this.pendingFrames.set(frameIndex, { resolve, reject });
      this.frameQueue.push({ frameIndex, pixels });
      this.processFrameQueue();
    });
  }

  async generate(
    file: File,
    mediaFileId: string,
    onProgress: (progress: number) => void,
    checkCancelled: () => boolean,
    saveFrame: (frame: { id: string; mediaFileId: string; frameIndex: number; blob: Blob }) => Promise<void>
  ): Promise<GeneratorResult | null> {
    this.onProgress = onProgress;
    this.checkCancelled = checkCancelled;
    this.isCancelled = false;
    this.processedFrames = 0;
    this.samples = [];
    this.decodedFrames.clear();
    this.frameTimestamps = [];

    // eslint-disable-next-line no-async-promise-executor
    return new Promise(async (resolve, reject) => {
      this.resolveGeneration = resolve;

      try {
        // Check for WebCodecs support
        if (!('VideoDecoder' in window)) {
          reject(new Error('WebCodecs VideoDecoder not available in this browser'));
          return;
        }

        // Check for WebGPU support
        const device = engine.getDevice();
        if (!device) {
          reject(new Error('WebGPU device not available'));
          return;
        }

        // Log GPU info for verification
        const adapterInfo = (device as any).adapterInfo;
        log.info('GPU ACCELERATION ACTIVE');
        log.debug('GPU Device', {
          vendor: adapterInfo?.vendor || 'unknown',
          architecture: adapterInfo?.architecture || 'unknown',
          device: adapterInfo?.device || 'unknown',
          description: adapterInfo?.description || 'WebGPU Device',
        });

        // Load file with MP4Box
        const loaded = await this.loadWithMP4Box(file);
        if (!loaded) {
          reject(new Error('Failed to parse video file or no supported codec found'));
          return;
        }

        log.info(`Video loaded: ${this.videoTrack!.video.width}x${this.videoTrack!.video.height}, targeting ${this.outputWidth}x${this.outputHeight} at ${PROXY_FPS}fps`);

        // Initialize GPU resize pipeline
        this.resizePipeline = new ProxyResizePipeline(device);
        this.resizePipeline.initializeAtlas(
          this.videoTrack!.video.width,
          this.videoTrack!.video.height,
          PROXY_MAX_WIDTH
        );

        // Update output dimensions from pipeline
        const dims = this.resizePipeline.getFrameDimensions();
        this.outputWidth = dims.width;
        this.outputHeight = dims.height;

        // Calculate target frame timestamps (at PROXY_FPS)
        for (let i = 0; i < this.totalFrames; i++) {
          this.frameTimestamps.push(i / PROXY_FPS);
        }

        // Initialize decoder
        this.initDecoder();

        // Process samples in batches
        try {
          await this.processSamplesGPU(mediaFileId, saveFrame);
        } catch (firstError) {
          log.warn('First decode attempt failed, trying without description...');

          // Reset state
          this.decodedFrames.clear();
          this.processedFrames = 0;

          // Try without description (some browsers handle this differently)
          if (this.codecConfig?.description) {
            const configWithoutDesc: VideoDecoderConfig = {
              codec: this.codecConfig.codec,
              codedWidth: this.codecConfig.codedWidth,
              codedHeight: this.codecConfig.codedHeight,
            };

            try {
              const support = await VideoDecoder.isConfigSupported(configWithoutDesc);
              if (support.supported) {
                log.info('Retrying with config without description...');
                this.codecConfig = configWithoutDesc;
                this.decoder?.close();
                this.initDecoder();
                await this.processSamplesGPU(mediaFileId, saveFrame);
              } else {
                throw firstError;
              }
            } catch (retryError) {
              log.error('Retry also failed', retryError);
              throw firstError;
            }
          } else {
            throw firstError;
          }
        }

      } catch (error) {
        log.error('Generation failed', error);
        reject(error);
      }
    });
  }

  private async loadWithMP4Box(file: File): Promise<boolean> {
    // eslint-disable-next-line no-async-promise-executor
    return new Promise(async (resolve) => {
      this.mp4File = MP4Box.createFile();
      const mp4File = this.mp4File!;
      let expectedSamples = 0;
      let samplesReady = false;
      let codecReady = false;

      const checkComplete = () => {
        if (codecReady && samplesReady) {
          log.info(`Extracted ${this.samples.length} samples from video`);
          resolve(true);
        }
      };

      mp4File.onReady = async (info: { videoTracks: MP4VideoTrack[] }) => {
        if (info.videoTracks.length === 0) {
          resolve(false);
          return;
        }

        this.videoTrack = info.videoTracks[0];
        const track = this.videoTrack;
        expectedSamples = track.nb_samples;

        // Calculate output dimensions (will be refined by GPU pipeline)
        let width = track.video.width;
        let height = track.video.height;
        if (width > PROXY_MAX_WIDTH) {
          height = Math.round((PROXY_MAX_WIDTH / width) * height);
          width = PROXY_MAX_WIDTH;
        }
        this.outputWidth = width;
        this.outputHeight = height;

        this.duration = track.duration / track.timescale;
        this.totalFrames = Math.ceil(this.duration * PROXY_FPS);

        // Get codec config with fallback support
        const trak = this.mp4File!.getTrackById(track.id);
        const codecString = this.getCodecString(track.codec, trak);

        log.debug(`Detected codec: ${codecString}, expecting ${expectedSamples} samples...`);

        // Get AVC description (SPS/PPS) for H.264
        let description: Uint8Array | undefined;
        if (codecString.startsWith('avc1')) {
          const avcC = trak?.mdia?.minf?.stbl?.stsd?.entries?.[0]?.avcC;
          if (avcC) {
            // Create avcC box as Uint8Array for VideoDecoder description
            // The description should be the raw avcC content (without box header)
            const stream = new (MP4Box as any).DataStream(undefined, 0, (MP4Box as any).DataStream.BIG_ENDIAN);
            avcC.write(stream);
            // stream.position tells us how many bytes were actually written
            // Skip 8 bytes for box header (4 bytes size + 4 bytes 'avcC' type)
            const totalWritten = stream.position || stream.buffer.byteLength;
            if (totalWritten > 8) {
              description = new Uint8Array(stream.buffer.slice(8, totalWritten));
              log.debug(`Got AVC description: ${description.length} bytes (from ${totalWritten} total)`);
              // Log first few bytes for debugging
              const hex = Array.from(description.slice(0, 16)).map(b => b.toString(16).padStart(2, '0')).join(' ');
              log.debug(`AVC description starts with: ${hex}`);
            } else {
              log.warn(`avcC box too small: ${totalWritten} bytes`);
            }
          } else {
            log.warn('No avcC box found in track');
          }
        }

        // Try to find a supported codec configuration
        const config = await this.findSupportedCodec(codecString, track.video.width, track.video.height, description);
        if (!config) {
          log.warn('No supported codec configuration found');
          resolve(false);
          return;
        }

        this.codecConfig = config;
        codecReady = true;

        // Extract all samples
        log.debug(`Setting extraction options for track ${track.id}...`);
        mp4File.setExtractionOptions(track.id, null, { nbSamples: Infinity });
        mp4File.start();

        // Force re-process already buffered data
        mp4File.flush();

        log.debug('Extraction started, waiting for samples...');

        // If no samples after a short delay, something is wrong
        setTimeout(() => {
          if (this.samples.length === 0) {
            log.warn(`No samples received after start(). Track has ${expectedSamples} samples.`);
          }
        }, 500);

        checkComplete();
      };

      mp4File.onSamples = (_trackId: number, _ref: any, samples: Sample[]) => {
        this.samples.push(...samples);
        log.debug(`Received ${samples.length} samples (total: ${this.samples.length}/${expectedSamples})`);
        if (this.samples.length >= expectedSamples) {
          samplesReady = true;
          checkComplete();
        }
      };

      mp4File.onError = (error: string) => {
        log.error('MP4Box error', error);
        resolve(false);
      };

      // Read entire file
      const fileData = await file.arrayBuffer();

      try {
        // First pass: parse file structure (triggers onReady)
        const buffer1 = fileData.slice(0) as MP4ArrayBuffer;
        buffer1.fileStart = 0;
        mp4File.appendBuffer(buffer1);
        mp4File.flush();

        // Wait for onReady and codec check to complete
        await new Promise(r => setTimeout(r, 500));

        if (!codecReady) {
          log.warn('Codec not ready after first pass');
          // Wait longer
          await new Promise(r => setTimeout(r, 1000));
        }

        if (codecReady && this.samples.length === 0) {
          // Second pass: re-append to extract samples now that extraction options are set
          log.debug('Re-appending data to extract samples...');
          const buffer2 = fileData.slice(0) as MP4ArrayBuffer;
          buffer2.fileStart = 0;
          mp4File.appendBuffer(buffer2);
          mp4File.flush();
        }

        // Give time for samples to be extracted
        setTimeout(() => {
          if (!samplesReady && this.samples.length > 0) {
            log.debug(`Timeout: proceeding with ${this.samples.length} samples`);
            samplesReady = true;
            checkComplete();
          } else if (!this.videoTrack) {
            log.warn('Timeout: no video track found');
            resolve(false);
          } else if (this.samples.length === 0) {
            log.error('No samples extracted after re-append');
            resolve(false);
          }
        }, 2000);
      } catch (e) {
        log.error('File read error', e);
        resolve(false);
      }
    });
  }

  private getCodecString(codec: string, trak: any): string {
    // Handle different codec types
    if (codec.startsWith('avc1')) {
      // H.264/AVC
      const avcC = trak?.mdia?.minf?.stbl?.stsd?.entries?.[0]?.avcC;
      if (avcC) {
        const profile = avcC.AVCProfileIndication.toString(16).padStart(2, '0');
        const compat = avcC.profile_compatibility.toString(16).padStart(2, '0');
        const level = avcC.AVCLevelIndication.toString(16).padStart(2, '0');
        return `avc1.${profile}${compat}${level}`;
      }
      return 'avc1.640028'; // Fallback to high profile
    }

    if (codec.startsWith('hvc1') || codec.startsWith('hev1')) {
      // H.265/HEVC
      return codec;
    }

    if (codec.startsWith('vp09')) {
      return codec;
    }

    if (codec.startsWith('av01')) {
      return codec;
    }

    return codec;
  }

  /**
   * Try multiple codec configurations until one is supported
   */
  private async findSupportedCodec(
    baseCodec: string,
    width: number,
    height: number,
    description?: Uint8Array
  ): Promise<VideoDecoderConfig | null> {
    // Common H.264 codec strings to try
    const h264Fallbacks = [
      baseCodec,
      'avc1.42001e', // Baseline L3.0
      'avc1.4d001e', // Main L3.0
      'avc1.64001e', // High L3.0
      'avc1.640028', // High L4.0
      'avc1.4d0028', // Main L4.0
      'avc1.42E01E', // Constrained Baseline
      'avc1.4D401E', // Main
      'avc1.640029', // High L4.1
    ];

    const codecsToTry = baseCodec.startsWith('avc1') ? h264Fallbacks : [baseCodec];

    log.debug(`Testing ${codecsToTry.length} codec configurations for ${width}x${height}...`);
    if (description) {
      log.debug(`Using AVC description (${description.length} bytes) for H.264 decoding`);
    }

    // Try with hardware acceleration preferred
    for (const codec of codecsToTry) {
      const config: VideoDecoderConfig = {
        codec,
        codedWidth: width,
        codedHeight: height,
        hardwareAcceleration: 'prefer-hardware',
        // Include description for AVC/H.264 (required for proper decoding)
        ...(description && { description }),
      };

      try {
        const support = await VideoDecoder.isConfigSupported(config);
        log.debug(`Codec ${codec}: ${support.supported ? 'supported' : 'not supported'}`);
        if (support.supported) {
          return config;
        }
      } catch (e) {
        log.debug(`Codec ${codec}: error - ${e}`);
      }
    }

    log.warn(`No supported codec found for ${baseCodec}`);
    return null;
  }

  private initDecoder() {
    if (!this.codecConfig) return;

    let decodedCount = 0;
    let errorCount = 0;
    let lastError: any = null;

    this.decoder = new VideoDecoder({
      output: (frame) => {
        decodedCount++;
        this.handleDecodedFrame(frame);
      },
      error: (error) => {
        errorCount++;
        lastError = error;
        // Only log first few errors to avoid spam
        if (errorCount <= 5) {
          log.error('Decoder error', error.message || error);
        }
        if (errorCount === 5) {
          log.warn('Suppressing further decoder errors...');
        }
      },
    });

    log.debug(`VideoDecoder created, state: ${this.decoder.state}`);

    this.decoder.configure(this.codecConfig);
    log.debug('Decoder configured', {
      codec: this.codecConfig.codec,
      size: `${this.codecConfig.codedWidth}x${this.codecConfig.codedHeight}`,
      hasDescription: !!this.codecConfig.description,
      descriptionSize: this.codecConfig.description ?
        (this.codecConfig.description as Uint8Array).byteLength : 0,
    });

    // Store counters for later logging
    (this.decoder as any)._decodedCount = () => decodedCount;
    (this.decoder as any)._errorCount = () => errorCount;
    (this.decoder as any)._lastError = () => lastError;
  }

  private handleDecodedFrame(frame: VideoFrame) {
    // Find the closest target frame index for this timestamp
    const timestamp = frame.timestamp / 1_000_000; // Convert to seconds
    const frameIndex = Math.round(timestamp * PROXY_FPS);

    // Log first few frames and every 50th frame
    const frameCount = this.decodedFrames.size + 1;
    if (frameCount <= 3 || frameCount % 50 === 0) {
      log.debug(`Frame decoded: index=${frameIndex}, timestamp=${timestamp.toFixed(2)}s, size=${frame.codedWidth}x${frame.codedHeight}, total=${frameCount}`);
    }

    if (frameIndex >= 0 && frameIndex < this.totalFrames) {
      // Check if we already have this frame (avoid duplicates)
      const existing = this.decodedFrames.get(frameIndex);
      if (existing) {
        existing.close(); // Close old frame
      }
      // Store frame for batch processing
      this.decodedFrames.set(frameIndex, frame);
    } else {
      frame.close();
    }

    // CRITICAL: Process frames when buffer gets full to release decoder memory
    // NVIDIA hardware decoders have limited DPB (Decoded Picture Buffer)
    if (this.decodedFrames.size >= BATCH_SIZE && this.pendingBatchProcess) {
      this.pendingBatchProcess();
    }
  }

  // Callback to trigger batch processing from decode loop
  private pendingBatchProcess: (() => void) | null = null;

  private async processSamplesGPU(
    mediaFileId: string,
    saveFrame: (frame: { id: string; mediaFileId: string; frameIndex: number; blob: Blob }) => Promise<void>
  ): Promise<void> {
    if (!this.decoder || !this.resizePipeline) return;

    // Sort samples by DTS (decode order) to ensure proper decoding
    const sortedSamples = [...this.samples].sort((a, b) => a.dts - b.dts);

    // Count keyframes for diagnostics
    const keyframeCount = sortedSamples.filter(s => s.is_sync).length;
    const deltaCount = sortedSamples.length - keyframeCount;
    log.info(`Decoding ${sortedSamples.length} samples (${keyframeCount} keyframes, ${deltaCount} delta frames)...`);

    // Find first keyframe to start decoding from
    const firstKeyframeIdx = sortedSamples.findIndex(s => s.is_sync);
    if (firstKeyframeIdx === -1) {
      log.error('No keyframes found in video!');
      throw new Error('No keyframes found');
    }
    if (firstKeyframeIdx > 0) {
      log.debug(`Skipping ${firstKeyframeIdx} samples before first keyframe`);
    }

    // Performance tracking
    const startTime = performance.now();
    let _totalGpuTime = 0;
    let _totalEncodeTime = 0;
    let batchCount = 0;
    const dbBatch: { id: string; mediaFileId: string; frameIndex: number; blob: Blob }[] = [];

    // Helper function to process accumulated frames
    const processAccumulatedFrames = async () => {
      if (this.decodedFrames.size < BATCH_SIZE) return;

      // Sort and get frames to process
      const sortedIndices = Array.from(this.decodedFrames.keys()).sort((a, b) => a - b);
      const batchIndices = sortedIndices.slice(0, BATCH_SIZE);
      const batchFrames: VideoFrame[] = [];
      const batchFrameIndices: number[] = [];

      for (const frameIndex of batchIndices) {
        const frame = this.decodedFrames.get(frameIndex);
        if (frame) {
          batchFrames.push(frame);
          batchFrameIndices.push(frameIndex);
          this.decodedFrames.delete(frameIndex);
        }
      }

      if (batchFrames.length > 0) {
        try {
          batchCount++;

          // GPU batch resize
          const gpuStart = performance.now();
          const pixelArrays = await this.resizePipeline!.processBatch(batchFrames);
          const gpuEnd = performance.now();
          _totalGpuTime += gpuEnd - gpuStart;

          // CRITICAL: Close video frames immediately to release decoder buffer
          for (const frame of batchFrames) {
            frame.close();
          }

          // Encode frames in parallel
          const encodeStart = performance.now();
          const expectedPixelSize = this.outputWidth * this.outputHeight * 4;

          const encodePromises = pixelArrays.map((pixels, i) => {
            if (!pixels || pixels.byteLength !== expectedPixelSize) {
              return Promise.resolve(new Blob([], { type: 'image/webp' }));
            }
            return this.encodeFrameAsync(batchFrameIndices[i], pixels);
          });

          const blobs = await Promise.all(encodePromises);
          const encodeEnd = performance.now();
          _totalEncodeTime += encodeEnd - encodeStart;

          // Log batch performance
          if (batchCount % 5 === 0 || batchCount === 1) {
            log.debug(`Batch ${batchCount}: GPU=${(gpuEnd - gpuStart).toFixed(1)}ms, Frames=${batchFrames.length}, Decoded=${this.decodedFrames.size} pending`);
          }

          // Save frames
          for (let i = 0; i < blobs.length; i++) {
            const blob = blobs[i];
            if (blob && blob.size > 0) {
              const frameIndex = batchFrameIndices[i];
              const frameId = `${mediaFileId}_${frameIndex.toString().padStart(6, '0')}`;
              dbBatch.push({ id: frameId, mediaFileId, frameIndex, blob });
              this.processedFrames++;
            }
          }

          this.onProgress?.(Math.round((this.processedFrames / this.totalFrames) * 100));

          // Save DB batch periodically
          if (dbBatch.length >= DB_BATCH_SIZE) {
            for (const f of dbBatch) {
              await saveFrame(f);
            }
            dbBatch.length = 0;
          }

        } catch (e) {
          log.error('GPU batch processing error', e);
          for (const frame of batchFrames) {
            frame.close();
          }
        }
      }
    };

    // Set up callback for streaming processing
    let processingPromise: Promise<void> | null = null;
    this.pendingBatchProcess = () => {
      if (!processingPromise) {
        processingPromise = processAccumulatedFrames().then(() => {
          processingPromise = null;
        });
      }
    };

    // Decode samples with streaming processing
    let decodeErrors = 0;
    let samplesDecoded = 0;
    const MAX_PENDING_FRAMES = BATCH_SIZE * 2; // Keep at most 2 batches worth of frames

    log.debug(`Starting streaming decode (max ${MAX_PENDING_FRAMES} pending frames)...`);
    const decodeStartTime = performance.now();

    for (let i = firstKeyframeIdx; i < sortedSamples.length; i++) {
      const sample = sortedSamples[i];

      if (this.checkCancelled?.()) {
        this.isCancelled = true;
        break;
      }

      if (this.decoder.state === 'closed') {
        log.error('Decoder was closed unexpectedly');
        break;
      }

      // Wait if we have too many pending frames (release decoder buffer pressure)
      let waitCount = 0;
      while (this.decodedFrames.size >= MAX_PENDING_FRAMES) {
        await processAccumulatedFrames();
        await new Promise(resolve => setTimeout(resolve, 5));
        waitCount++;
        if (waitCount > 400) { // 2 second timeout
          log.warn(`Frame processing stalled, ${this.decodedFrames.size} frames pending`);
          break;
        }
      }

      const chunk = new EncodedVideoChunk({
        type: sample.is_sync ? 'key' : 'delta',
        timestamp: (sample.cts / sample.timescale) * 1_000_000,
        duration: (sample.duration / sample.timescale) * 1_000_000,
        data: sample.data,
      });

      try {
        this.decoder.decode(chunk);
        samplesDecoded++;
        if (samplesDecoded % 100 === 0) {
          log.debug(`Submitted ${samplesDecoded}/${sortedSamples.length} samples, ${this.decodedFrames.size} frames pending, ${this.processedFrames} processed`);
        }
      } catch (e) {
        decodeErrors++;
        if (decodeErrors <= 5) {
          log.error(`Decode error on sample ${sample.number}`, e);
        }
        if (decodeErrors > 50) {
          log.error('Too many decode errors, stopping');
          break;
        }
      }

      // Small yield to allow decoder output callback to fire
      if (i % 10 === 0) {
        await new Promise(resolve => setTimeout(resolve, 0));
      }
    }

    const decodeLoopTime = performance.now() - decodeStartTime;
    log.debug(`Decode loop complete: ${samplesDecoded} samples in ${decodeLoopTime.toFixed(0)}ms`);

    // Wait for decoder to output remaining frames
    // Windows NVIDIA decoders can be very slow, so we actively wait
    log.debug(`Waiting for decoder to output frames (currently ${this.decodedFrames.size} pending)...`);

    const expectedFrames = Math.min(sortedSamples.length - firstKeyframeIdx, this.totalFrames);
    const maxWaitTime = 120000; // 2 minutes max wait
    const waitStart = performance.now();
    let lastFrameCount = this.decodedFrames.size + this.processedFrames;
    let stallCount = 0;

    // Keep processing while decoder outputs frames
    while (performance.now() - waitStart < maxWaitTime) {
      const currentFrameCount = this.decodedFrames.size + this.processedFrames;

      // Process any accumulated frames
      if (this.decodedFrames.size >= BATCH_SIZE) {
        await processAccumulatedFrames();
      }

      // Check if we got all expected frames
      if (this.processedFrames >= expectedFrames * 0.95) {
        log.debug(`Got ${this.processedFrames}/${expectedFrames} frames (95%+), continuing...`);
        break;
      }

      // Check for stall (no new frames for 5 seconds)
      if (currentFrameCount === lastFrameCount) {
        stallCount++;
        if (stallCount > 100) { // 5 seconds (100 * 50ms)
          log.warn(`Decoder stalled for 5s at ${currentFrameCount} frames`);
          break;
        }
      } else {
        stallCount = 0;
        lastFrameCount = currentFrameCount;
      }

      // Log progress periodically
      if (stallCount === 0 && currentFrameCount % 50 === 0) {
        const elapsed = ((performance.now() - waitStart) / 1000).toFixed(1);
        log.debug(`Decoder progress: ${this.processedFrames} processed, ${this.decodedFrames.size} pending (${elapsed}s elapsed)`);
      }

      await new Promise(resolve => setTimeout(resolve, 50));
    }

    // Try to flush any remaining frames
    try {
      if (this.decoder.state !== 'closed') {
        log.debug('Final decoder flush...');
        await Promise.race([
          this.decoder.flush(),
          new Promise<void>((_, reject) => setTimeout(() => reject(new Error('Flush timeout')), 5000))
        ]);
      }
    } catch (e) {
      // Ignore flush timeout at this point
    }

    // Process any remaining frames
    log.debug(`Processing ${this.decodedFrames.size} remaining frames...`);
    while (this.decodedFrames.size > 0) {
      // Process whatever we have, even if less than BATCH_SIZE
      const sortedIndices = Array.from(this.decodedFrames.keys()).sort((a, b) => a - b);
      const batchIndices = sortedIndices.slice(0, Math.min(BATCH_SIZE, sortedIndices.length));
      const batchFrames: VideoFrame[] = [];
      const batchFrameIndices: number[] = [];

      for (const frameIndex of batchIndices) {
        const frame = this.decodedFrames.get(frameIndex);
        if (frame) {
          batchFrames.push(frame);
          batchFrameIndices.push(frameIndex);
          this.decodedFrames.delete(frameIndex);
        }
      }

      if (batchFrames.length === 0) break;

      try {
        batchCount++;
        const pixelArrays = await this.resizePipeline!.processBatch(batchFrames);

        for (const frame of batchFrames) {
          frame.close();
        }

        const expectedPixelSize = this.outputWidth * this.outputHeight * 4;
        const encodePromises = pixelArrays.map((pixels, i) => {
          if (!pixels || pixels.byteLength !== expectedPixelSize) {
            return Promise.resolve(new Blob([], { type: 'image/webp' }));
          }
          return this.encodeFrameAsync(batchFrameIndices[i], pixels);
        });

        const blobs = await Promise.all(encodePromises);

        for (let i = 0; i < blobs.length; i++) {
          const blob = blobs[i];
          if (blob && blob.size > 0) {
            const frameIndex = batchFrameIndices[i];
            const frameId = `${mediaFileId}_${frameIndex.toString().padStart(6, '0')}`;
            dbBatch.push({ id: frameId, mediaFileId, frameIndex, blob });
            this.processedFrames++;
          }
        }

        this.onProgress?.(Math.round((this.processedFrames / this.totalFrames) * 100));
      } catch (e) {
        log.error('Final batch error', e);
        for (const frame of batchFrames) {
          frame.close();
        }
      }
    }

    // Save remaining DB batch
    for (const f of dbBatch) {
      await saveFrame(f);
    }

    // Clean up
    this.pendingBatchProcess = null;
    this.resizePipeline.destroy();
    this.resizePipeline = null;

    if (this.isCancelled) {
      this.resolveGeneration?.(null);
    } else {
      const totalTime = performance.now() - startTime;
      const fps = this.processedFrames / (totalTime / 1000);

      log.info('GPU Processing Complete');
      log.info('Performance Summary', {
        totalFrames: this.processedFrames,
        totalBatches: batchCount,
        totalTime: `${(totalTime / 1000).toFixed(1)}s`,
        framesPerSecond: fps.toFixed(1),
      });

      this.resolveGeneration?.({
        frameCount: this.processedFrames,
        fps: PROXY_FPS,
      });
    }
  }

  destroy() {
    this.decoder?.close();
    this.workers.forEach(w => w.terminate());
    for (const frame of this.decodedFrames.values()) {
      frame.close();
    }
    this.decodedFrames.clear();
    this.resizePipeline?.destroy();
  }
}

// Singleton instance
let generatorInstance: ProxyGeneratorGPU | null = null;

export function getProxyGenerator(): ProxyGeneratorGPU {
  if (!generatorInstance) {
    generatorInstance = new ProxyGeneratorGPU();
  }
  return generatorInstance;
}

export { ProxyGeneratorGPU, PROXY_FPS, PROXY_QUALITY, PROXY_MAX_WIDTH };
